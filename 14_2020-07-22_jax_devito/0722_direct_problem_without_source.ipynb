{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Acoustic Wave\n",
    "---\n",
    "- Model Setup: [this link](https://github.com/devitocodes/devito/blob/master/examples/seismic/tutorials/01_modelling.ipynb)\n",
    "\n",
    "- target: $c(x, z)^2$.\n",
    "\n",
    "- rescaling: $x' = x/1000, z' = z/1000, t' = t/1000$.\n",
    "\n",
    "---\n",
    "\n",
    "# Direct Problem only,  without Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"0722_direct_problem_without_source\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, jax.nn\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"../../\")\n",
    "\t\n",
    "from Seismic_wave_inversion_PINN.data_utils import *\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siren_layer_params(key, scale, m, n):\n",
    "\tw_key, b_key = random.split(key)\n",
    "\treturn random.uniform(w_key, (m, n), jnp.float32, minval = -scale, maxval = scale), jnp.zeros((n, ), jnp.float32)\n",
    "\n",
    "def init_siren_params(key, layers, c, w0):\n",
    "\tkeys = random.split(key, len(layers))\n",
    "\treturn [siren_layer_params(keys[0], w0*jnp.sqrt(c/layers[0]), layers[0], layers[1])] + \\\n",
    "\t\t\t[siren_layer_params(k, jnp.sqrt(c/m), m, n) for m, n, k in zip(layers[1:-1], layers[2:], keys[1:])]\n",
    "\n",
    "layers = [3, 512, 512, 512, 512, 512, 1] # (x, z, t) -> p\n",
    "c = 6.0\n",
    "w0 = 30.0\n",
    "lambda_0 = 1e-5\n",
    "direct_params = init_siren_params(random.PRNGKey(0), layers, c, w0)\n",
    "\n",
    "inverse_NAME = \"0722_pretrain_inverse_problem\"\n",
    "inverse_iteration = 1000000\n",
    "inverse_params = np.load(\"models/{}/inverse_model/iteration_{}/params.npy\".format(inverse_NAME, inverse_iteration), allow_pickle=True)\n",
    "inverse_params = [[jnp.asarray(arr) for arr in Arr] for Arr in inverse_params]\n",
    "\n",
    "@jax.jit\n",
    "def scalar_direct_model(params, x, z, t):\n",
    "\tx_ = jnp.hstack([x, z, t])\n",
    "\tfor w, b in params[:-1]:\n",
    "\t\tx_ = jnp.sin(jnp.dot(x_, w) + b)\n",
    "\treturn jnp.sum(jnp.dot(x_, params[-1][0]) + params[-1][1])\n",
    "\n",
    "@jax.jit\n",
    "def scalar_inverse_model(params, x, z):\n",
    "\tx_ = jnp.hstack([x, z])\n",
    "\tfor w, b in params[:-1]:\n",
    "\t\tx_ = jnp.sin(jnp.dot(x_, w) + b)\n",
    "\treturn jnp.sum(jnp.dot(x_, params[-1][0]) + params[-1][1])\n",
    "\n",
    "direct_model = jax.jit(jax.vmap(scalar_direct_model, in_axes = (None, 0, 0, 0)))\n",
    "inverse_model = jax.jit(jax.vmap(scalar_inverse_model, in_axes = (None, 0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def mse(pred, true):\n",
    "\treturn jnp.mean(jnp.square(pred - true))\n",
    "\n",
    "@jax.jit\n",
    "def l2_regularization(params, lambda_0):\n",
    "\tres = 0\n",
    "\tfor p in params:\n",
    "\t\tres += jnp.sum(jnp.square(p[0]))\n",
    "\treturn res*lambda_0\n",
    "\n",
    "@jax.jit\n",
    "def scalar_dp_dx(params, x, z, t):\n",
    "    return jnp.sum(jax.grad(scalar_direct_model, 1)(params, x, z, t))\n",
    "\n",
    "@jax.jit\n",
    "def scalar_dp_dz(params, x, z, t):\n",
    "    return jnp.sum(jax.grad(scalar_direct_model, 2)(params, x, z, t))\n",
    "\n",
    "@jax.jit\n",
    "def scalar_dp_dt(params, x, z, t):\n",
    "    return jnp.sum(jax.grad(scalar_direct_model, 3)(params, x, z, t))\n",
    "\n",
    "@jax.jit\n",
    "def dp_dxx(params, x, z, t):\n",
    "    return jax.grad(scalar_dp_dx, 1)(params, x, z, t)\n",
    "\n",
    "@jax.jit\n",
    "def dp_dzz(params, x, z, t):\n",
    "    return jax.grad(scalar_dp_dz, 2)(params, x, z, t)\n",
    "\n",
    "@jax.jit\n",
    "def dp_dtt(params, x, z, t):\n",
    "    return jax.grad(scalar_dp_dt, 3)(params, x, z, t)\n",
    "\n",
    "@jax.jit\n",
    "def loss_fn_(params, batch):\n",
    "# \tdirect_params, inverse_params = params\n",
    "# \tcollocation, dirichlet = batch[\"collocation\"], batch[\"dirichlet\"]\n",
    "\tdirect_params = params\n",
    "\tdirichlet = batch[\"dirichlet\"]\n",
    "    \n",
    "# \tc = inverse_model(inverse_params, collocation.x, collocation.z)\n",
    "# \tdp_dtt_ = dp_dtt(direct_params, collocation.x, collocation.z, collocation.t)\n",
    "# \tdp_dxx_ = dp_dxx(direct_params, collocation.x, collocation.z, collocation.t)\n",
    "# \tdp_dzz_ = dp_dzz(direct_params, collocation.x, collocation.z, collocation.t)\n",
    "\tp_pred = direct_model(direct_params, dirichlet.x, dirichlet.z, dirichlet.t).reshape((-1, 1))\n",
    "\t\n",
    "# \tloss_c = mse(dp_dtt_ - c**2*(dp_dxx_ + dp_dzz_), 0)\n",
    "\tloss_d = mse(p_pred, dirichlet.p)\n",
    "# \treturn loss_c, loss_d\n",
    "\treturn loss_d\n",
    "\n",
    "@jax.jit\n",
    "def loss_fn(params, batch):\n",
    "# \tloss_c, loss_d = loss_fn_(params, batch)\n",
    "# \treturn w_c*loss_c + w_d*loss_d + l2_regularization(params[0], lambda_0) + l2_regularization(params[1], lambda_0)\n",
    "\tloss_d = loss_fn_(params, batch)\n",
    "\treturn w_d*loss_d + l2_regularization(params, lambda_0)\n",
    "\n",
    "@jax.jit\n",
    "def step(i, opt_state, batch):\n",
    "\tparams = get_params(opt_state)\n",
    "\tgrad = jax.grad(loss_fn, 0)(params, batch)\n",
    "\treturn opt_update(i, grad, opt_state)\n",
    "\n",
    "@jax.jit\n",
    "def evaluate(params, batch):\n",
    "# \tloss_c, loss_d = loss_fn_(params, batch)\n",
    "# \treturn w_c*loss_c + w_d*loss_d, loss_c, loss_d\n",
    "\treturn loss_fn_(params, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_Dirichlet = namedtuple(\"dataset_Dirichlet\", [\"x\", \"z\", \"t\", \"p\"])\n",
    "dataset_Collocation = namedtuple(\"dataset_Collocation\", [\"x\", \"z\", \"t\"])\n",
    "\n",
    "x0 = z0 = t0 = 1000\n",
    "\n",
    "domain = np.array([0.0, 1000.0]) / x0\n",
    "T_max = 1000.0 / t0\n",
    "x_s = 500.0 / x0\n",
    "z_s = 20.0 / z0\n",
    "\n",
    "import pickle\n",
    "with open(\"../9_2020-07-14-devito/dataset_single_source.pkl\", \"rb\") as file:\n",
    "\t[x, t, p, _, _] = pickle.load(file)\n",
    "t_index = (t >= 200)\n",
    "t_ = t[t_index] / t0\n",
    "x /= x0\n",
    "\t\n",
    "txz_d = tensor_grid([t_, x, [z_s]])\n",
    "t_d, x_d, z_d = txz_d[:, 0:1], txz_d[:, 1:2], txz_d[:, 2:3]\n",
    "p_d = p[t_index, :].reshape((-1, 1))\n",
    "\n",
    "n_cx = n_cz = n_ct = 100000\n",
    "x_c, z_c, t_c = np.linspace(*domain, n_cx).reshape((-1, 1)), np.linspace(*domain, n_cz).reshape((-1, 1)), np.linspace(0, T_max, n_ct).reshape((-1, 1))\n",
    "\n",
    "collocation = dataset_Collocation(*(map(lambda x: jnp.array(x), [np.vstack([x_c, x_d]), np.vstack([z_c, z_d]), np.vstack([t_c, t_d])])))\n",
    "dirichlet = dataset_Dirichlet(*map(lambda x: jnp.array(x), [x_d, z_d, t_d, p_d]))\n",
    "\n",
    "class Batch_Generator:\n",
    "\tdef __init__(self, dataset, batch_size):\n",
    "\t\tself.dataset = dataset\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.index = np.arange(dataset[0].shape[0])\n",
    "\t\tnp.random.shuffle(self.index)\n",
    "\t\tself.pointer = 0\n",
    "\t\t\n",
    "\tdef __iter__(self):\n",
    "\t\treturn self\n",
    "\t\n",
    "\tdef __next__(self):\n",
    "\t\tif self.pointer >= len(self.index):\n",
    "\t\t\tnp.random.shuffle(self.index)\n",
    "\t\t\tself.pointer = 0\n",
    "\t\tself.pointer += self.batch_size\n",
    "\t\treturn [d[self.pointer-self.batch_size:self.pointer, :] for d in self.dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/07/24, 13:41:01, Iteration: 1000, Train Loss: 2.1913e-04\n",
      "2020/07/24, 13:41:08, Iteration: 2000, Train Loss: 4.7827e-04\n",
      "2020/07/24, 13:41:15, Iteration: 3000, Train Loss: 3.6159e-04\n",
      "2020/07/24, 13:41:21, Iteration: 4000, Train Loss: 5.5528e-04\n",
      "2020/07/24, 13:41:28, Iteration: 5000, Train Loss: 1.4201e-04\n",
      "2020/07/24, 13:41:35, Iteration: 6000, Train Loss: 2.9216e-04\n",
      "2020/07/24, 13:41:42, Iteration: 7000, Train Loss: 3.5833e-04\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "iterations = 10000\n",
    "print_every = 1000\n",
    "save_every = 10000\n",
    "batch_size_collocation = 10000\n",
    "batch_size_dirichlet = 10000\n",
    "w_c = 1.0\n",
    "w_d = 1.0\n",
    "\n",
    "Collocation = Batch_Generator(collocation, batch_size_collocation)\n",
    "Dirichlet = Batch_Generator(dirichlet, batch_size_dirichlet)\n",
    "# params = [direct_params, inverse_params]\n",
    "params = direct_params\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "opt_state = opt_init(params)\n",
    "for iteration in range(1, iterations+1):\n",
    "\tbatch = {\n",
    "\t\t\"dirichlet\": dataset_Dirichlet(*next(Dirichlet)),\n",
    "\t\t\"collocation\": dataset_Collocation(*next(Collocation))\n",
    "\t}\n",
    "\topt_state = step(iteration, opt_state, batch)\n",
    "\tif iteration % print_every == 0:\n",
    "# \t\tnames = [\"Loss\", \"collocation\", \"dirichlet\"]\n",
    "\t\tnames = [\"Loss\"]\n",
    "\t\tparams_ = get_params(opt_state)\n",
    "\t\tlosses = [evaluate(params_, batch)]\n",
    "\t\tprint(\"{}, Iteration: {}, Train\".format(get_time(), iteration) + \\\n",
    "\t\t\t  ','.join([\" {}: {:.4e}\".format(name, loss) for name, loss in zip(names, losses)]))\n",
    "\tif iteration % save_every == 0:\n",
    "\t\tparams_ = np.asarray(get_params(opt_state), dtype = object)\n",
    "\t\tsave_path = \"models/{}/iteration_{}/params.npy\".format(NAME, iteration)\n",
    "\t\tif not os.path.exists(os.path.dirname(save_path)):\n",
    "\t\t\tos.makedirs(os.path.dirname(save_path))\n",
    "\t\tnp.save(save_path, params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pred = direct_model(get_params(opt_state), dirichlet.x, dirichlet.z, dirichlet.t).reshape((len(t_), len(x)))\n",
    "p_true = dirichlet.p.reshape((len(t_), len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib.cm import cool\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "cmap = cool\n",
    "norm = Normalize(vmin=-5.0, vmax=8.0)\n",
    "\n",
    "X, T = np.meshgrid(x, t_)\n",
    "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "fig.subplots_adjust(right = 1.0)\n",
    "\n",
    "im0 = ax[0].contourf(X, T, p_true, cmap = cmap, norm = norm, levels = 1000)\n",
    "ax[0].set_title(\"true\")\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "mpl.colorbar.ColorbarBase(cax, cmap = cmap, norm = norm, orientation='vertical')\n",
    "\n",
    "# norm = mpl.colors.Normalize(vmin=1.0, vmax=3.0)\n",
    "im1 = ax[1].contourf(X, T, p_pred, cmap = cmap, norm = norm, levels = 1000)\n",
    "ax[1].set_title(\"pred\")\n",
    "ax[1].set_xlabel(\"\")\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "mpl.colorbar.ColorbarBase(cax, cmap = cmap, norm = norm, orientation='vertical')\n",
    "\n",
    "norm = mpl.colors.Normalize(vmin=-1e-1, vmax=1e-1)\n",
    "im2 = ax[2].contourf(X, T, p_true - p_pred, cmap = cmap, norm = norm, levels = 1000)\n",
    "ax[2].set_title(\"MSE: {}\".format(np.mean(np.square(p_true - p_pred))))\n",
    "divider = make_axes_locatable(ax[2])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "mpl.colorbar.ColorbarBase(cax, cmap = cmap, norm = norm, orientation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain = np.array([[0.0, 0.0], [1.0, 1.0]])\n",
    "# def c_fn(x, z):\n",
    "# \treturn np.piecewise(z, [z >= 0.5, z < 0.5], [2.5, 1.5])\n",
    "\n",
    "# x_test = np.linspace(domain[0, 0], domain[1, 0], 100).reshape((-1, 1))\n",
    "# z_test = np.linspace(domain[0, 1], domain[1, 1], 100).reshape((-1, 1))\n",
    "# xz_test = tensor_grid([x_test, z_test])\n",
    "# c_test = c_fn(xz_test[:, 0:1], xz_test[:, 1:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_pred = inverse_model(get_params(opt_state)[1], xz_test[:, 0:1], xz_test[:, 1:2]).reshape((-1, 1))\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.cm import cool\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "cmap = cool\n",
    "norm = Normalize(vmin=1.0, vmax=3.0)\n",
    "\n",
    "X, Z = np.meshgrid(x_test, z_test)\n",
    "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "fig.subplots_adjust(right = 1.0)\n",
    "\n",
    "im0 = ax[0].contourf(X, Z, c_test.reshape((len(z_test), len(x_test))), cmap = cmap, norm = norm, levels = 1000)\n",
    "ax[0].set_title(\"true\")\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "mpl.colorbar.ColorbarBase(cax, cmap = cmap, norm = norm, orientation='vertical')\n",
    "\n",
    "norm = mpl.colors.Normalize(vmin=1.0, vmax=3.0)\n",
    "im1 = ax[1].contourf(X, Z, c_pred.reshape((len(z_test), len(x_test))), cmap = cmap, norm = norm, levels = 1000)\n",
    "ax[1].set_title(\"pred\")\n",
    "ax[1].set_xlabel(\"\")\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "mpl.colorbar.ColorbarBase(cax, cmap = cmap, norm = norm, orientation='vertical')\n",
    "\n",
    "norm = mpl.colors.Normalize(vmin=-1e-1, vmax=1e-1)\n",
    "im2 = ax[2].contourf(X, Z, c_test.reshape((len(z_test), len(x_test)))-c_pred.reshape((len(z_test), len(x_test))), cmap = cmap, norm = norm, levels = 1000)\n",
    "ax[2].set_title(\"MSE: {}\".format(np.mean(np.square(c_test - c_pred))))\n",
    "divider = make_axes_locatable(ax[2])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "mpl.colorbar.ColorbarBase(cax, cmap = cmap, norm = norm, orientation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider\n",
    "$$\n",
    "p(x, 0) = e^{-25x^2}\\cos(\\frac{1}{\\pi}\\cos(\\pi x)/\\varepsilon), \\ q(x, 0) = e^{-25x^2}\\sin(\\frac{1}{\\pi}\\cos(\\pi x)/\\varepsilon).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"ic_func_approx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, jax.nn\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"../../\")\n",
    "\t\n",
    "from Seismic_wave_inversion_PINN.data_utils import *\n",
    "from Seismic_wave_inversion_PINN.jax_model import *\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key = random.PRNGKey(1)\n",
    "key, subkey = random.split(key, 2)\n",
    "\n",
    "layers = [2] + [32]*2 + [2] # (x, t) -> (u, v)\n",
    "c0 = 6.0\n",
    "w0 = jnp.array([[1.0], [1.0]]) # (w_x, w_t)\n",
    "w1 = 1.0\n",
    "lambda_0 = 1e-7\n",
    "direct_params = init_siren_params(subkey, layers, c0, w0, w1)\n",
    "# direct_params = init_tanh_params(subkey, layers)\n",
    "\n",
    "domain = jnp.array([[-0.25, 0.], [0.25, 0.5]])\n",
    "epsilon = 1.0\n",
    "V = 0.0\n",
    "\n",
    "@jax.jit\n",
    "def model(params, xt):\n",
    "\t# first, normalize to [-1, 1] <- enforce periodic bc\n",
    "# \txt = jnp.sin(2.0*jnp.pi*(xt - domain[0, :])/(domain[1, :]-domain[0, :]) - jnp.pi)\n",
    "\tfor w, b in params[:-1]:\n",
    "\t\txt = jnp.sin(jnp.dot(xt, w) + b)\n",
    "\treturn jnp.dot(xt, params[-1][0]) + params[-1][1]\n",
    "\n",
    "jacobian = jacrev_fn(model)\n",
    "hessian = hessian_fn(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaloss = mae\n",
    "\n",
    "jit_conservation = lambda i: jax.partial(jax.jit, static_argnums = i)\n",
    "\n",
    "@jax.jit\n",
    "def loss_fn_(params, batch):\n",
    "\tcollocation, dirichlet = batch[\"collocation\"], batch[\"dirichlet\"]\n",
    "\tdirect_params = params\n",
    "\t\n",
    "# \tuv_c = model(direct_params, jnp.hstack([collocation.x, collocation.t]))\n",
    "# \tu_c, v_c = uv_c[:, 0:1], uv_c[:, 1:2]\n",
    "\t\n",
    "# \t# jacobian[i] = [[du/dx, du/dt],\n",
    "# \t#                [dv/dx, dv/dt]]\n",
    "# \t# i: the i^th input\n",
    "# \tduv_dxt_c = jacobian(direct_params, jnp.hstack([collocation.x, collocation.t]))\n",
    "# \tdu_dt_c, dv_dt_c = duv_dxt_c[:, 0:1, 1], duv_dxt_c[:, 1:2, 1]\n",
    "\t\n",
    "# \t# hessian[i] = [\n",
    "#     #\t\t\t\t[[du/dxx, du/dxy],\n",
    "# \t#                [du/dxy, du/dyy]],\n",
    "# \t#               [[dv/dxx, dv/dxy],\n",
    "# \t#                [dv/dxy, dv/dyy]]\n",
    "# \t#              ]\n",
    "# \tduv_dxxtt_c = hessian(direct_params, jnp.hstack([collocation.x, collocation.t]))\n",
    "# \tdu_dxx_c, dv_dxx_c = duv_dxxtt_c[:, 0:1, 0, 0], duv_dxxtt_c[:, 1:2, 0, 0] \n",
    "\t\t\n",
    "\tuv_d = model(direct_params, jnp.hstack([dirichlet.x, dirichlet.t]))\n",
    "\tu_d, v_d = uv_d[:, 0:1], uv_d[:, 1:2]\n",
    "\t\n",
    "# \tloss_c1 = metaloss(epsilon*du_dt_c + 0.5*epsilon**2*dv_dxx_c - V*v_c, 0)\n",
    "# \tloss_c2 = metaloss(epsilon*dv_dt_c - 0.5*epsilon**2*du_dxx_c + V*u_c, 0)\n",
    "# \tloss_c = loss_c1 + loss_c2\n",
    "\tloss_c = 0\n",
    "\t\n",
    "\tloss_d1 = metaloss(u_d, dirichlet.u)\n",
    "\tloss_d2 = metaloss(v_d, dirichlet.v)\n",
    "\tloss_d = loss_d1 + loss_d2\n",
    "\t\n",
    "\treturn loss_c, loss_d\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def loss_fn(params, batch):\n",
    "\tw = batch[\"weights\"]\n",
    "\tloss_c, loss_d = loss_fn_(params, batch)\n",
    "\treturn w[\"c\"]*loss_c + w[\"d\"]*loss_d + l2_regularization(params, lambda_0)\n",
    "\n",
    "@jax.jit\n",
    "def step(i, opt_state, batch):\n",
    "\tparams = get_params(opt_state)\n",
    "\tgrad = jax.grad(loss_fn, 0)(params, batch)\n",
    "\treturn opt_update(i, grad, opt_state)\n",
    "\n",
    "@jax.jit\n",
    "def evaluate(params, batch):\n",
    "\tw = batch[\"weights\"]\n",
    "\tloss_c, loss_d = loss_fn_(params, batch)\n",
    "\treturn w[\"c\"]*loss_c + w[\"d\"]*loss_d, loss_c, loss_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0_fn = lambda x, t: np.exp(-25*x**2)*np.cos(1/(np.pi*epsilon)*np.cos(np.pi*x))\n",
    "v0_fn = lambda x, t: np.exp(-25*x**2)*np.sin(1/(np.pi*epsilon)*np.cos(np.pi*x))\n",
    "x0 = np.linspace(*domain[:, 0], 1000)\n",
    "t0 = np.zeros_like(x0)\n",
    "u0 = u0_fn(x0, t0)\n",
    "v0 = v0_fn(x0, t0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "f, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "ax[0].plot(x0, u0)\n",
    "ax[0].set_title(\"u, t=0\")\n",
    "ax[0].grid()\n",
    "ax[0].set_ylim([-1, 1])\n",
    "ax[1].plot(x0, v0)\n",
    "ax[1].set_title(\"v, t=0\")\n",
    "ax[1].grid()\n",
    "ax[1].set_ylim([-1, 1])\n",
    "ax[2].plot(x0, np.sqrt(u0**2+v0**2))\n",
    "ax[2].set_title(\"|h|, t=0\")\n",
    "ax[2].grid()\n",
    "ax[2].set_ylim([-1, 1])\n",
    "plt.show()\n",
    "\n",
    "key, *subkeys = random.split(key, 3)\n",
    "\n",
    "n_i = 1000\n",
    "x_i = random.uniform(subkeys[0], (n_i, 1), jnp.float32, *domain[:, 0])\n",
    "t_i = jnp.zeros_like(x_i)\n",
    "u_i = u0_fn(x_i, t_i)\n",
    "v_i = v0_fn(x_i, t_i)\n",
    "\n",
    "n_cx = 1000\n",
    "x_c = jnp.linspace(*domain[:, 0], n_cx).reshape((-1, 1))\n",
    "\n",
    "dataset_Dirichlet = namedtuple(\"dataset_Dirichlet\", [\"x\", \"t\", \"u\", \"v\"])\n",
    "dataset_Collocation = namedtuple(\"dataset_Collocation\", [\"x\", \"t\"])\n",
    "\n",
    "dirichlet = dataset_Dirichlet(x_i, t_i, u_i, v_i)\n",
    "collocation = dataset_Collocation(jnp.vstack([dirichlet.x]),\n",
    "\t\t\t\t\t\t\t\t jnp.vstack([dirichlet.t]))\n",
    "\n",
    "class Time_Marching_Generator:\n",
    "\tdef __init__(self, key, spatial_points, temporal_domain, batch_size, iterations, update_every):\n",
    "\t\tself.key = key\n",
    "\t\tself.spatial_points = spatial_points\n",
    "\t\tself.domain = temporal_domain\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.iterations = iterations\n",
    "\t\tself._count1 = -1\n",
    "\t\tself._count2 = update_every\n",
    "\t\tself.update_every = update_every\n",
    "\t\t\n",
    "\tdef _update(self, key, tmax):\n",
    "\t\tself._t = random.uniform(key, (self.batch_size, 1), jnp.float32, self.domain[0], tmax)\n",
    "\t\t\n",
    "\tdef __iter__(self):\n",
    "\t\treturn self\n",
    "\t\n",
    "\tdef __next__(self):\n",
    "\t\tif self._count2 == self.update_every:\n",
    "\t\t\tself._count1 = max(self.iterations, self._count1 + 1)\n",
    "\t\t\ttmax = self.domain[0] + (self.domain[1]-self.domain[0])*self._count1/self.iterations\n",
    "\t\t\tself.key, subkey = random.split(self.key)\n",
    "\t\t\tself._update(subkey, tmax)\n",
    "\t\t\tself._count2 = 0\n",
    "\t\telse:\n",
    "\t\t\tself._count2 += 1\n",
    "\t\treturn self.spatial_points, self._t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pre-train\n",
    "\n",
    "lr = 1e-3\n",
    "start_iteration = 0\n",
    "iterations = 100000\n",
    "print_every = 100\n",
    "save_every = 10000\n",
    "batch_size = {\"dirichlet\": 1000, \"collocation\": 1000}\n",
    "weights = {\"c\": 0, \"d\": 1.0}\n",
    "\n",
    "key, *subkeys = random.split(key, 5)\n",
    "Dirichlet = Batch_Generator(subkeys[0], dirichlet, batch_size[\"dirichlet\"])\n",
    "Collocation = Time_Marching_Generator(subkeys[3], x_c, domain[:, 1], n_cx, iterations, 1)\n",
    "\n",
    "params = direct_params\n",
    "opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "opt_state = opt_init(params)\n",
    "hist = {\"iter\": [], \"loss\": []}\n",
    "\n",
    "for iteration in range(start_iteration, start_iteration+iterations+1):\n",
    "\td = next(Dirichlet)\n",
    "\tc = next(Collocation)\n",
    "\tbatch = {\n",
    "\t\t\"dirichlet\": dataset_Dirichlet(*d),\n",
    "\t\t\"collocation\": dataset_Collocation(jnp.vstack([d[0], c[0]]), jnp.vstack([d[1], c[1]])),\n",
    "\t\t\"weights\": weights\n",
    "\t}\n",
    "\topt_state = step(iteration, opt_state, batch)\n",
    "\tif (iteration-start_iteration) % print_every == 0:\n",
    "\t\tnames = [\"Loss\", \"c\", \"d\"]\n",
    "\t\tparams_ = get_params(opt_state)\n",
    "\t\tlosses = evaluate(params_, batch)\n",
    "\t\tprint(\"{}, Iteration: {}, Train\".format(get_time(), iteration) + \\\n",
    "\t\t\t  ','.join([\" {}: {:.4e}\".format(name, loss) for name, loss in zip(names, losses)]))\n",
    "\t\thist[\"iter\"].append(iteration)\n",
    "\t\thist[\"loss\"].append(losses)\n",
    "\tif (iteration-start_iteration) % save_every == 0:\n",
    "\t\tparams_ = np.asarray(get_params(opt_state), dtype = object)\n",
    "\t\tsave_path = \"models/{}/iteration_{}/params.npy\".format(NAME, iteration)\n",
    "\t\tif not os.path.exists(os.path.dirname(save_path)):\n",
    "\t\t\tos.makedirs(os.path.dirname(save_path))\n",
    "\t\tnp.save(save_path, params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "uv_true = loadmat(\"ex1_epsilon_1.0.mat\")[\"u\"].T\n",
    "\n",
    "from matplotlib import animation\n",
    "%matplotlib notebook\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "lines = []\n",
    "for i in range(3):\n",
    "    line1, = ax[i].plot([], [], lw = 1.5, label = \"true\")\n",
    "    line2, = ax[i].plot([], [], lw = 1.5, label = \"pred\")\n",
    "    lines.extend([line1, line2])\n",
    "    ax[i].set_xlim([-0.25, 0.25])\n",
    "    ax[i].set_ylim([-1, 1])\n",
    "    ax[i].legend()\n",
    "    ax[i].grid()\n",
    "    \n",
    "def init():\n",
    "\tfor line in lines:\n",
    "\t\tline.set_data([], [])\n",
    "\treturn lines\n",
    "\n",
    "params_ = get_params(opt_state)\n",
    "\n",
    "x_test = jnp.linspace(*domain[:, 0], 1024)\n",
    "t_test = jnp.linspace(*domain[:, 1], 51)\n",
    "xt_tests = [tensor_grid([x_test, ti]) for ti in t_test]\n",
    "uv_preds = [model(params_, xt_test) for xt_test in xt_tests]\n",
    "u_preds, v_preds = [uv_pred[:, 0:1] for uv_pred in uv_preds], [uv_pred[:, 1:2] for uv_pred in uv_preds]\n",
    "\n",
    "def animate(i):\n",
    "\tu_pred, v_pred = u_preds[i], v_preds[i]\n",
    "\tu_true, v_true = np.real(uv_true[i, :]), np.imag(uv_true[i, :])\n",
    "\t\n",
    "\tlines[0].set_data(x_test, u_true)\n",
    "\tlines[1].set_data(x_test, u_pred)\n",
    "\tax[0].set_title(\"u, t = {:.2f}\".format(t_test[i]))\n",
    "    \n",
    "\tlines[2].set_data(x_test, v_true)\n",
    "\tlines[3].set_data(x_test, v_pred)\n",
    "\tax[1].set_title(\"v, t = {:.2f}\".format(t_test[i]))\n",
    "\n",
    "\tlines[4].set_data(x_test, np.sqrt(u_true**2+v_true**2))\n",
    "\tlines[5].set_data(x_test, np.sqrt(u_pred**2+v_pred**2))\n",
    "\tax[2].set_title(\"|h|, t = {:.2f}\".format(t_test[i]))\n",
    "\n",
    "\treturn lines\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames = len(t_test), interval = 1000, blit = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

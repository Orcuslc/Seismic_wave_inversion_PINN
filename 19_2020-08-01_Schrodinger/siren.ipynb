{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Schrodinger equation\n",
    "---\n",
    "(Example From PINNs)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&ih_t + 0.5h_{xx} + |h|^2 h = 0, \\ (x, t) \\in [-5, 5]\\times [0, \\pi/2], \\\\ \n",
    "&h(0, x) = 2 \\sech (x), \\\\\n",
    "&h(t, -5) = h(t, 5), \\\\\n",
    "&h_x(t, -5) = h_x(t, 5).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Consider \n",
    "$$\n",
    "h(t, x) = u(t, x) + iv(t, x), \n",
    "$$\n",
    "where $u, v$ are real-valued functions. Then the equation can be given by\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&u_t + 0.5v_{xx} + (u^2+v^2)v = 0, \\\\\n",
    "&-v_t + 0.5u_{xx} + (u^2+v^2)u = 0, \\\\\n",
    "&u(0, x) = 2\\sech (x), \\ v(0, x) = 0, \\\\\n",
    "&u(t, -5) = u(t, 5), \\ v(t, -5) = v(t, 5), \\\\\n",
    "&u_x(t, -5) = u_x(t, 5), \\ v_x(t, -5) = v_x(t, 5).\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"siren\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, jax.nn\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"../../\")\n",
    "\t\n",
    "from Seismic_wave_inversion_PINN.data_utils import *\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chuan/.local/lib/python3.8/site-packages/jax/lib/xla_bridge.py:125: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "def siren_layer_params(key, scale, m, n):\n",
    "\tw_key, b_key = random.split(key)\n",
    "\treturn random.uniform(w_key, (m, n), jnp.float32, minval = -scale, maxval = scale), jnp.zeros((n, ), jnp.float32)\n",
    "\n",
    "def init_siren_params(key, layers, c0, w0):\n",
    "\tkeys = random.split(key, len(layers))\n",
    "\treturn [siren_layer_params(keys[0], w0*jnp.sqrt(c0/layers[0]), layers[0], layers[1])] + \\\n",
    "\t\t\t[siren_layer_params(k, jnp.sqrt(c0/m), m, n) for m, n, k in zip(layers[1:-1], layers[2:], keys[1:])]\n",
    "\n",
    "layers = [2, 128, 128, 128, 128, 128, 2] # (x, t) -> (u, v)\n",
    "c0 = 1.0\n",
    "w0 = 10.0\n",
    "lambda_0 = 1e-10\n",
    "direct_params = init_siren_params(random.PRNGKey(0), layers, c0, w0)\n",
    "\n",
    "@jax.jit\n",
    "def scalar_u_model(params, x, t):\n",
    "\tx_ = jnp.hstack([x, t])\n",
    "\tfor w, b in params[:-1]:\n",
    "\t\tx_ = jnp.sin(jnp.dot(x_, w) + b)\n",
    "\treturn jnp.sum(jnp.dot(x_, params[-1][0][:, 0:1]) + params[-1][1][0])\n",
    "\n",
    "@jax.jit\n",
    "def scalar_v_model(params, x, t):\n",
    "\tx_ = jnp.hstack([x, t])\n",
    "\tfor w, b in params[:-1]:\n",
    "\t\tx_ = jnp.sin(jnp.dot(x_, w) + b)\n",
    "\treturn jnp.sum(jnp.dot(x_, params[-1][0][:, 1:2]) + params[-1][1][1])\n",
    "\n",
    "u_model = jax.jit(jax.vmap(scalar_u_model, in_axes = (None, 0, 0)))\n",
    "v_model = jax.jit(jax.vmap(scalar_v_model, in_axes = (None, 0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def mse(pred, true):\n",
    "\treturn jnp.mean(jnp.square(pred - true))\n",
    "\n",
    "@jax.jit\n",
    "def l2_regularization(params, lambda_0):\n",
    "\tres = 0\n",
    "\tfor p in params:\n",
    "\t\tres += jnp.sum(jnp.square(p[0]))\n",
    "\treturn res*lambda_0\n",
    "\n",
    "@jax.jit\n",
    "def scalar_du_dx(params, x, t):\n",
    "    return jnp.sum(jax.grad(scalar_u_model, 1)(params, x, t))\n",
    "\n",
    "@jax.jit\n",
    "def scalar_du_dt(params, x, t):\n",
    "    return jnp.sum(jax.grad(scalar_u_model, 2)(params, x, t))\n",
    "\n",
    "du_dx = jax.jit(jax.vmap(scalar_du_dx, in_axes = (None, 0, 0)))\n",
    "du_dt = jax.jit(jax.vmap(scalar_du_dt, in_axes = (None, 0, 0)))\n",
    "\n",
    "@jax.jit\n",
    "def du_dxx(params, x, t):\n",
    "    return jax.grad(scalar_du_dx, 1)(params, x, t)\n",
    "\n",
    "@jax.jit\n",
    "def du_dtt(params, x, t):\n",
    "    return jax.grad(scalar_du_dt, 2)(params, x, t)\n",
    "\n",
    "@jax.jit\n",
    "def scalar_dv_dx(params, x, t):\n",
    "    return jnp.sum(jax.grad(scalar_v_model, 1)(params, x, t))\n",
    "\n",
    "@jax.jit\n",
    "def scalar_dv_dt(params, x, t):\n",
    "    return jnp.sum(jax.grad(scalar_v_model, 2)(params, x, t))\n",
    "\n",
    "dv_dx = jax.jit(jax.vmap(scalar_dv_dx, in_axes = (None, 0, 0)))\n",
    "dv_dt = jax.jit(jax.vmap(scalar_dv_dt, in_axes = (None, 0, 0)))\n",
    "\n",
    "@jax.jit\n",
    "def dv_dxx(params, x, t):\n",
    "    return jax.grad(scalar_dv_dx, 1)(params, x, t)\n",
    "\n",
    "@jax.jit\n",
    "def dv_dtt(params, x, t):\n",
    "    return jax.grad(scalar_dv_dt, 2)(params, x, t)\n",
    "\n",
    "@jax.jit\n",
    "def loss_fn_(params, batch):\n",
    "\tcollocation, dirichlet, periodic_bc = batch[\"collocation\"], batch[\"dirichlet\"], batch[\"periodic_bc\"]\n",
    "\tdirect_params = params\n",
    "\t\n",
    "\tu_c = u_model(direct_params, collocation.x, collocation.t)\n",
    "\tv_c = v_model(direct_params, collocation.x, collocation.t)\n",
    "\tdu_dt_c = du_dt(direct_params, collocation.x, collocation.t)\n",
    "\tdv_dt_c = dv_dt(direct_params, collocation.x, collocation.t)\n",
    "\tdu_dxx_c = du_dxx(direct_params, collocation.x, collocation.t)\n",
    "\tdv_dxx_c = dv_dxx(direct_params, collocation.x, collocation.t)\n",
    "\t\n",
    "\tu_l = u_model(direct_params, periodic_bc.l, periodic_bc.t)\n",
    "\tu_r = u_model(direct_params, periodic_bc.r, periodic_bc.t)\n",
    "\tv_l = v_model(direct_params, periodic_bc.l, periodic_bc.t)\n",
    "\tv_r = v_model(direct_params, periodic_bc.r, periodic_bc.t)\n",
    "\tdu_dx_l = du_dx(direct_params, periodic_bc.l, periodic_bc.t)\n",
    "\tdu_dx_r = du_dx(direct_params, periodic_bc.r, periodic_bc.t)\n",
    "\tdv_dx_l = dv_dx(direct_params, periodic_bc.l, periodic_bc.t)\n",
    "\tdv_dx_r = dv_dx(direct_params, periodic_bc.r, periodic_bc.t)\t\n",
    "\t\t\n",
    "\tu_d = u_model(direct_params, dirichlet.x, dirichlet.t).reshape((-1, 1))\n",
    "\tv_d = v_model(direct_params, dirichlet.x, dirichlet.t).reshape((-1, 1))\n",
    "\t\n",
    "\tloss_c1 = mse(du_dt_c + 0.5*dv_dxx_c + (u_c**2 + v_c**2)*v_c, 0)\n",
    "\tloss_c2 = mse(-dv_dt_c + 0.5*du_dxx_c + (u_c**2 + v_c**2)*u_c, 0)\n",
    "\tloss_c = loss_c1 + loss_c2\n",
    "\t\n",
    "\tloss_d1 = mse(u_d, dirichlet.u)\n",
    "\tloss_d2 = mse(v_d, dirichlet.v)\n",
    "\tloss_d = loss_d1 + loss_d2\n",
    "\t\n",
    "\tloss_pbc_d1 = mse(u_l, u_r)\n",
    "\tloss_pbc_d2 = mse(v_l, v_r)\n",
    "\tloss_pbc_n1 = mse(du_dx_l, du_dx_r)\n",
    "\tloss_pbc_n2 = mse(dv_dx_l, dv_dx_r)\n",
    "\tloss_pbc_d = loss_pbc_d1 + loss_pbc_d2\n",
    "\tloss_pbc_n = loss_pbc_n1 + loss_pbc_n2\n",
    "\t\n",
    "\treturn loss_c, loss_d, loss_pbc_d, loss_pbc_n\n",
    "\n",
    "@jax.jit\n",
    "def loss_fn(params, batch):\n",
    "\tw = batch[\"weights\"]\n",
    "\tloss_c, loss_d, loss_pbc_d, loss_pbc_n = loss_fn_(params, batch)\n",
    "\treturn w[\"c\"]*loss_c + w[\"d\"]*loss_d + w[\"pbc_d\"]*loss_pbc_d + w[\"pbc_n\"]*loss_pbc_n + l2_regularization(params, lambda_0)\n",
    "\n",
    "@jax.jit\n",
    "def step(i, opt_state, batch):\n",
    "\tparams = get_params(opt_state)\n",
    "\tgrad = jax.grad(loss_fn, 0)(params, batch)\n",
    "\treturn opt_update(i, grad, opt_state)\n",
    "\n",
    "@jax.jit\n",
    "def evaluate(params, batch):\n",
    "\tw = batch[\"weights\"]\n",
    "\tloss_c, loss_d, loss_pbc_d, loss_pbc_n = loss_fn_(params, batch)\n",
    "\treturn w[\"c\"]*loss_c + w[\"d\"]*loss_d + w[\"pbc_d\"]*loss_pbc_d + w[\"pbc_n\"]*loss_pbc_n, loss_c, loss_d, loss_pbc_d, loss_pbc_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = np.array([[-5, 5], [0, np.pi/2]])\n",
    "key = random.PRNGKey(1)\n",
    "key, *subkeys = random.split(key, 4)\n",
    "\n",
    "from scipy.io import loadmat\n",
    "data = loadmat(\"NLS.mat\")\n",
    "x, t, h = data[\"x\"].reshape((-1, 1)), data[\"tt\"].reshape((-1, 1)), data[\"uu\"].T\n",
    "u, v = np.real(h), np.imag(h)\n",
    "\n",
    "# ic\n",
    "n_i = 50\n",
    "ix_i = random.choice(subkeys[0], jnp.arange(len(x)), shape = (n_i, ), replace = False)\n",
    "x_i = x[ix_i, :]\n",
    "t_i = np.zeros_like(x_i)\n",
    "u_i = u[0, ix_i].reshape((-1, 1))\n",
    "v_i = v[0, ix_i].reshape((-1, 1))\n",
    "\n",
    "# bc\n",
    "n_b = 50\n",
    "ix_b = random.choice(subkeys[1], jnp.arange(len(t)), shape = (n_b, ), replace = False)\n",
    "t_b = t[ix_b, :]\n",
    "x_lb = np.ones_like(t_b)*domain[0, 0]\n",
    "x_rb = np.ones_like(t_b)*domain[0, 1]\n",
    "\n",
    "n_c = 20000\n",
    "from pyDOE import lhs\n",
    "xt_c = lhs(2, n_c)\n",
    "x_c = transform(xt_c[:, 0:1], *domain[0])\n",
    "t_c = transform(xt_c[:, 1:2], *domain[1])\n",
    "\n",
    "dataset_Dirichlet = namedtuple(\"dataset_Dirichlet\", [\"x\", \"t\", \"u\", \"v\"])\n",
    "dataset_Collocation = namedtuple(\"dataset_Collocation\", [\"x\", \"t\"])\n",
    "dataset_BC = namedtuple(\"dataset_BC\", [\"l\", \"r\", \"t\"])\n",
    "\n",
    "map_to_jnp_array = lambda x: map(lambda arr: jnp.array(arr), x)\n",
    "dirichlet = dataset_Dirichlet(*map_to_jnp_array([x_i, t_i, u_i, v_i]))\n",
    "periodic_bc = dataset_BC(*map_to_jnp_array([x_lb, x_rb, t_b]))\n",
    "collocation = dataset_Collocation(*map_to_jnp_array([jnp.vstack([dirichlet.x, periodic_bc.l, periodic_bc.r, x_c]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tjnp.vstack([dirichlet.t, periodic_bc.t, periodic_bc.t, t_c])]))\n",
    "\n",
    "class Batch_Generator:\n",
    "\tdef __init__(self, key, dataset, batch_size):\n",
    "\t\tself.key = key\n",
    "\t\tself.dataset = dataset\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.index = jnp.arange(dataset[0].shape[0])\n",
    "\t\tself.pointer = 0\n",
    "\t\tself._shuffle()\n",
    "\t\t\n",
    "\tdef _shuffle(self):\n",
    "\t\tkey, subkey = random.split(self.key)\n",
    "\t\tself.index = random.permutation(subkey, jnp.arange(self.dataset[0].shape[0]))\n",
    "\t\tself.key = key\n",
    "\t\t\n",
    "\tdef __iter__(self):\n",
    "\t\treturn self\n",
    "\t\n",
    "\tdef __next__(self):\n",
    "\t\tif self.pointer >= len(self.index):\n",
    "\t\t\tself._shuffle()\n",
    "\t\t\tself.pointer = 0\n",
    "\t\tself.pointer += self.batch_size\n",
    "\t\tindex_ = self.index[self.pointer-self.batch_size:self.pointer]\n",
    "\t\treturn [d[index_, :] for d in self.dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/08/02, 00:48:42, Iteration: 0, Train Loss: 9.8935e-01, c: 1.3233e-01, d: 8.0831e-01\n",
      "2020/08/02, 00:51:10, Iteration: 100, Train Loss: 3.9466e-01, c: 2.1591e-02, d: 3.7161e-01\n",
      "2020/08/02, 00:53:11, Iteration: 200, Train Loss: 1.1961e-01, c: 6.3821e-02, d: 5.4533e-02\n",
      "2020/08/02, 00:55:14, Iteration: 300, Train Loss: 9.4450e-02, c: 5.8385e-02, d: 3.4860e-02\n",
      "2020/08/02, 00:57:19, Iteration: 400, Train Loss: 8.7343e-02, c: 5.1154e-02, d: 3.5661e-02\n",
      "2020/08/02, 00:59:23, Iteration: 500, Train Loss: 8.5922e-02, c: 4.7202e-02, d: 3.7869e-02\n",
      "2020/08/02, 01:01:27, Iteration: 600, Train Loss: 8.2136e-02, c: 4.4397e-02, d: 3.7399e-02\n",
      "2020/08/02, 01:03:32, Iteration: 700, Train Loss: 8.5936e-02, c: 4.7181e-02, d: 3.8100e-02\n",
      "2020/08/02, 01:05:38, Iteration: 800, Train Loss: 9.0064e-02, c: 4.4636e-02, d: 4.4830e-02\n",
      "2020/08/02, 01:07:44, Iteration: 900, Train Loss: 8.5356e-02, c: 4.7248e-02, d: 3.7415e-02\n",
      "2020/08/02, 01:09:50, Iteration: 1000, Train Loss: 8.2809e-02, c: 4.6874e-02, d: 3.5266e-02\n",
      "2020/08/02, 01:11:57, Iteration: 1100, Train Loss: 8.3930e-02, c: 4.4723e-02, d: 3.8629e-02\n",
      "2020/08/02, 01:14:03, Iteration: 1200, Train Loss: 8.3034e-02, c: 4.2136e-02, d: 4.0594e-02\n",
      "2020/08/02, 01:16:11, Iteration: 1300, Train Loss: 8.0085e-02, c: 4.3790e-02, d: 3.6011e-02\n",
      "2020/08/02, 01:18:18, Iteration: 1400, Train Loss: 8.1060e-02, c: 4.3753e-02, d: 3.7037e-02\n",
      "2020/08/02, 01:20:26, Iteration: 1500, Train Loss: 8.0385e-02, c: 4.4492e-02, d: 3.5568e-02\n",
      "2020/08/02, 01:22:34, Iteration: 1600, Train Loss: 7.9831e-02, c: 4.3469e-02, d: 3.6108e-02\n",
      "2020/08/02, 01:24:42, Iteration: 1700, Train Loss: 8.4714e-02, c: 4.4937e-02, d: 3.9167e-02\n",
      "2020/08/02, 01:26:50, Iteration: 1800, Train Loss: 8.1508e-02, c: 4.4714e-02, d: 3.6473e-02\n",
      "2020/08/02, 01:28:59, Iteration: 1900, Train Loss: 7.9217e-02, c: 4.1972e-02, d: 3.6957e-02\n",
      "2020/08/02, 01:31:07, Iteration: 2000, Train Loss: 7.8745e-02, c: 4.3216e-02, d: 3.5172e-02\n",
      "2020/08/02, 01:33:16, Iteration: 2100, Train Loss: 8.0203e-02, c: 4.8172e-02, d: 3.1891e-02\n",
      "2020/08/02, 01:35:25, Iteration: 2200, Train Loss: 7.8651e-02, c: 4.2296e-02, d: 3.6102e-02\n",
      "2020/08/02, 01:37:34, Iteration: 2300, Train Loss: 8.1215e-02, c: 4.7527e-02, d: 3.3261e-02\n",
      "2020/08/02, 01:39:43, Iteration: 2400, Train Loss: 8.2213e-02, c: 4.9241e-02, d: 3.2329e-02\n",
      "2020/08/02, 01:41:53, Iteration: 2500, Train Loss: 8.0214e-02, c: 4.3292e-02, d: 3.6675e-02\n",
      "2020/08/02, 01:44:03, Iteration: 2600, Train Loss: 8.2185e-02, c: 4.6916e-02, d: 3.4914e-02\n",
      "2020/08/02, 01:46:13, Iteration: 2700, Train Loss: 7.9944e-02, c: 4.1773e-02, d: 3.7890e-02\n",
      "2020/08/02, 01:48:22, Iteration: 2800, Train Loss: 8.4251e-02, c: 4.6560e-02, d: 3.7032e-02\n",
      "2020/08/02, 01:50:33, Iteration: 2900, Train Loss: 7.9109e-02, c: 4.3898e-02, d: 3.4924e-02\n",
      "2020/08/02, 01:52:43, Iteration: 3000, Train Loss: 8.2182e-02, c: 4.4114e-02, d: 3.7833e-02\n",
      "2020/08/02, 01:54:54, Iteration: 3100, Train Loss: 7.8765e-02, c: 4.3957e-02, d: 3.4575e-02\n",
      "2020/08/02, 01:57:04, Iteration: 3200, Train Loss: 7.9473e-02, c: 4.4627e-02, d: 3.4433e-02\n",
      "2020/08/02, 01:59:16, Iteration: 3300, Train Loss: 7.9848e-02, c: 4.6759e-02, d: 3.2784e-02\n",
      "2020/08/02, 02:01:27, Iteration: 3400, Train Loss: 8.0401e-02, c: 4.5618e-02, d: 3.4311e-02\n",
      "2020/08/02, 02:03:38, Iteration: 3500, Train Loss: 7.9739e-02, c: 4.2528e-02, d: 3.6998e-02\n",
      "2020/08/02, 02:05:50, Iteration: 3600, Train Loss: 7.8565e-02, c: 4.2842e-02, d: 3.5481e-02\n",
      "2020/08/02, 02:08:01, Iteration: 3700, Train Loss: 8.0783e-02, c: 4.3972e-02, d: 3.6540e-02\n",
      "2020/08/02, 02:10:12, Iteration: 3800, Train Loss: 7.9574e-02, c: 4.4249e-02, d: 3.4645e-02\n",
      "2020/08/02, 02:12:23, Iteration: 3900, Train Loss: 7.9989e-02, c: 4.2605e-02, d: 3.6717e-02\n",
      "2020/08/02, 02:14:34, Iteration: 4000, Train Loss: 8.0122e-02, c: 4.4202e-02, d: 3.5695e-02\n",
      "2020/08/02, 02:16:46, Iteration: 4100, Train Loss: 7.9503e-02, c: 4.3807e-02, d: 3.5526e-02\n",
      "2020/08/02, 02:18:57, Iteration: 4200, Train Loss: 7.8382e-02, c: 4.2967e-02, d: 3.5168e-02\n",
      "2020/08/02, 02:21:09, Iteration: 4300, Train Loss: 8.1549e-02, c: 4.2139e-02, d: 3.9327e-02\n",
      "2020/08/02, 02:23:20, Iteration: 4400, Train Loss: 7.9014e-02, c: 4.3322e-02, d: 3.5511e-02\n",
      "2020/08/02, 02:25:32, Iteration: 4500, Train Loss: 7.8297e-02, c: 4.3043e-02, d: 3.5160e-02\n",
      "2020/08/02, 02:27:44, Iteration: 4600, Train Loss: 8.1618e-02, c: 4.4984e-02, d: 3.6066e-02\n",
      "2020/08/02, 02:29:56, Iteration: 4700, Train Loss: 8.0951e-02, c: 4.3518e-02, d: 3.7328e-02\n",
      "2020/08/02, 02:32:09, Iteration: 4800, Train Loss: 7.9731e-02, c: 4.3520e-02, d: 3.6020e-02\n",
      "2020/08/02, 02:34:21, Iteration: 4900, Train Loss: 7.8553e-02, c: 4.4505e-02, d: 3.3961e-02\n",
      "2020/08/02, 02:36:35, Iteration: 5000, Train Loss: 7.9854e-02, c: 4.3033e-02, d: 3.6533e-02\n",
      "2020/08/02, 02:38:48, Iteration: 5100, Train Loss: 7.9593e-02, c: 4.3912e-02, d: 3.5511e-02\n",
      "2020/08/02, 02:41:01, Iteration: 5200, Train Loss: 7.9609e-02, c: 4.4323e-02, d: 3.5136e-02\n",
      "2020/08/02, 02:43:14, Iteration: 5300, Train Loss: 7.9924e-02, c: 4.2312e-02, d: 3.7339e-02\n",
      "2020/08/02, 02:45:28, Iteration: 5400, Train Loss: 7.9660e-02, c: 4.6861e-02, d: 3.2518e-02\n",
      "2020/08/02, 02:47:42, Iteration: 5500, Train Loss: 8.3590e-02, c: 4.7952e-02, d: 3.5132e-02\n",
      "2020/08/02, 02:49:55, Iteration: 5600, Train Loss: 7.8860e-02, c: 4.6522e-02, d: 3.2237e-02\n",
      "2020/08/02, 02:52:09, Iteration: 5700, Train Loss: 8.2519e-02, c: 4.2703e-02, d: 3.9715e-02\n",
      "2020/08/02, 02:54:22, Iteration: 5800, Train Loss: 7.9094e-02, c: 4.6180e-02, d: 3.2704e-02\n",
      "2020/08/02, 02:56:36, Iteration: 5900, Train Loss: 7.9703e-02, c: 4.0832e-02, d: 3.8488e-02\n",
      "2020/08/02, 02:58:50, Iteration: 6000, Train Loss: 7.9367e-02, c: 4.0521e-02, d: 3.8693e-02\n",
      "2020/08/02, 03:01:04, Iteration: 6100, Train Loss: 7.8858e-02, c: 4.1106e-02, d: 3.7607e-02\n",
      "2020/08/02, 03:03:18, Iteration: 6200, Train Loss: 8.1076e-02, c: 4.5232e-02, d: 3.5740e-02\n",
      "2020/08/02, 03:05:33, Iteration: 6300, Train Loss: 7.8278e-02, c: 4.3192e-02, d: 3.4860e-02\n",
      "2020/08/02, 03:07:47, Iteration: 6400, Train Loss: 7.7506e-02, c: 4.2326e-02, d: 3.5068e-02\n",
      "2020/08/02, 03:10:01, Iteration: 6500, Train Loss: 7.9187e-02, c: 4.4944e-02, d: 3.4082e-02\n",
      "2020/08/02, 03:12:15, Iteration: 6600, Train Loss: 8.4426e-02, c: 4.2447e-02, d: 4.1778e-02\n",
      "2020/08/02, 03:14:29, Iteration: 6700, Train Loss: 7.9261e-02, c: 4.5127e-02, d: 3.3926e-02\n",
      "2020/08/02, 03:16:44, Iteration: 6800, Train Loss: 7.9218e-02, c: 4.2824e-02, d: 3.6080e-02\n",
      "2020/08/02, 03:18:58, Iteration: 6900, Train Loss: 7.9057e-02, c: 4.4315e-02, d: 3.4424e-02\n",
      "2020/08/02, 03:21:13, Iteration: 7000, Train Loss: 7.8802e-02, c: 4.4150e-02, d: 3.4477e-02\n",
      "2020/08/02, 03:23:28, Iteration: 7100, Train Loss: 7.8148e-02, c: 4.2669e-02, d: 3.5395e-02\n",
      "2020/08/02, 03:25:42, Iteration: 7200, Train Loss: 7.8480e-02, c: 4.5219e-02, d: 3.3167e-02\n",
      "2020/08/02, 03:27:57, Iteration: 7300, Train Loss: 7.8937e-02, c: 4.5634e-02, d: 3.3131e-02\n",
      "2020/08/02, 03:30:12, Iteration: 7400, Train Loss: 7.9099e-02, c: 4.2299e-02, d: 3.6631e-02\n",
      "2020/08/02, 03:32:27, Iteration: 7500, Train Loss: 7.8513e-02, c: 4.4201e-02, d: 3.4253e-02\n",
      "2020/08/02, 03:34:42, Iteration: 7600, Train Loss: 7.8815e-02, c: 4.4878e-02, d: 3.3799e-02\n",
      "2020/08/02, 03:36:56, Iteration: 7700, Train Loss: 7.8353e-02, c: 4.3955e-02, d: 3.4131e-02\n",
      "2020/08/02, 03:39:12, Iteration: 7800, Train Loss: 7.8398e-02, c: 4.2487e-02, d: 3.5781e-02\n",
      "2020/08/02, 03:41:27, Iteration: 7900, Train Loss: 7.8538e-02, c: 4.2855e-02, d: 3.5653e-02\n",
      "2020/08/02, 03:43:42, Iteration: 8000, Train Loss: 7.8731e-02, c: 4.2225e-02, d: 3.6355e-02\n",
      "2020/08/02, 03:45:57, Iteration: 8100, Train Loss: 7.7483e-02, c: 4.3017e-02, d: 3.4351e-02\n",
      "2020/08/02, 03:48:12, Iteration: 8200, Train Loss: 7.8655e-02, c: 4.4847e-02, d: 3.3661e-02\n",
      "2020/08/02, 03:50:27, Iteration: 8300, Train Loss: 7.9106e-02, c: 4.3563e-02, d: 3.5382e-02\n",
      "2020/08/02, 03:52:42, Iteration: 8400, Train Loss: 7.9660e-02, c: 4.6136e-02, d: 3.3183e-02\n",
      "2020/08/02, 03:54:57, Iteration: 8500, Train Loss: 7.8319e-02, c: 4.4833e-02, d: 3.3431e-02\n",
      "2020/08/02, 03:57:13, Iteration: 8600, Train Loss: 7.8413e-02, c: 4.3768e-02, d: 3.4546e-02\n",
      "2020/08/02, 03:59:28, Iteration: 8700, Train Loss: 7.7816e-02, c: 4.4443e-02, d: 3.3278e-02\n",
      "2020/08/02, 04:01:42, Iteration: 8800, Train Loss: 8.0144e-02, c: 4.4730e-02, d: 3.5309e-02\n",
      "2020/08/02, 04:03:57, Iteration: 8900, Train Loss: 7.8640e-02, c: 4.4375e-02, d: 3.4210e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/08/02, 04:06:13, Iteration: 9000, Train Loss: 7.8276e-02, c: 4.2923e-02, d: 3.5144e-02\n",
      "2020/08/02, 04:08:29, Iteration: 9100, Train Loss: 7.8285e-02, c: 4.2412e-02, d: 3.5702e-02\n",
      "2020/08/02, 04:10:43, Iteration: 9200, Train Loss: 7.8736e-02, c: 4.4240e-02, d: 3.4446e-02\n",
      "2020/08/02, 04:12:58, Iteration: 9300, Train Loss: 7.7439e-02, c: 4.4068e-02, d: 3.3280e-02\n",
      "2020/08/02, 04:15:14, Iteration: 9400, Train Loss: 7.9443e-02, c: 4.3303e-02, d: 3.6057e-02\n",
      "2020/08/02, 04:17:30, Iteration: 9500, Train Loss: 7.7425e-02, c: 4.3602e-02, d: 3.3725e-02\n",
      "2020/08/02, 04:19:45, Iteration: 9600, Train Loss: 7.8830e-02, c: 4.1537e-02, d: 3.7173e-02\n",
      "2020/08/02, 04:22:01, Iteration: 9700, Train Loss: 7.9193e-02, c: 4.7042e-02, d: 3.2004e-02\n",
      "2020/08/02, 04:24:16, Iteration: 9800, Train Loss: 7.9074e-02, c: 4.4664e-02, d: 3.4373e-02\n",
      "2020/08/02, 04:26:32, Iteration: 9900, Train Loss: 7.7897e-02, c: 4.3435e-02, d: 3.4400e-02\n",
      "2020/08/02, 04:28:48, Iteration: 10000, Train Loss: 8.1617e-02, c: 4.5222e-02, d: 3.6324e-02\n",
      "2020/08/02, 04:31:03, Iteration: 10100, Train Loss: 7.8230e-02, c: 4.2006e-02, d: 3.6195e-02\n",
      "2020/08/02, 04:33:18, Iteration: 10200, Train Loss: 7.9847e-02, c: 4.2949e-02, d: 3.6832e-02\n",
      "2020/08/02, 04:35:33, Iteration: 10300, Train Loss: 8.2632e-02, c: 4.8280e-02, d: 3.3977e-02\n",
      "2020/08/02, 04:37:49, Iteration: 10400, Train Loss: 7.8681e-02, c: 4.5845e-02, d: 3.2776e-02\n",
      "2020/08/02, 04:40:03, Iteration: 10500, Train Loss: 7.8233e-02, c: 4.2580e-02, d: 3.5585e-02\n",
      "2020/08/02, 04:42:19, Iteration: 10600, Train Loss: 7.8646e-02, c: 4.0605e-02, d: 3.7883e-02\n",
      "2020/08/02, 04:44:34, Iteration: 10700, Train Loss: 7.9066e-02, c: 4.5239e-02, d: 3.3769e-02\n",
      "2020/08/02, 04:46:49, Iteration: 10800, Train Loss: 7.8615e-02, c: 4.2589e-02, d: 3.5941e-02\n",
      "2020/08/02, 04:49:04, Iteration: 10900, Train Loss: 7.7989e-02, c: 4.2452e-02, d: 3.5479e-02\n",
      "2020/08/02, 04:51:19, Iteration: 11000, Train Loss: 7.8249e-02, c: 4.4606e-02, d: 3.3555e-02\n",
      "2020/08/02, 04:53:34, Iteration: 11100, Train Loss: 7.9151e-02, c: 4.5923e-02, d: 3.3159e-02\n",
      "2020/08/02, 04:55:49, Iteration: 11200, Train Loss: 7.8584e-02, c: 4.1763e-02, d: 3.6789e-02\n",
      "2020/08/02, 04:58:04, Iteration: 11300, Train Loss: 7.7855e-02, c: 4.1256e-02, d: 3.6523e-02\n",
      "2020/08/02, 05:00:20, Iteration: 11400, Train Loss: 7.7220e-02, c: 4.3301e-02, d: 3.3861e-02\n",
      "2020/08/02, 05:02:34, Iteration: 11500, Train Loss: 7.8574e-02, c: 4.5857e-02, d: 3.2645e-02\n",
      "2020/08/02, 05:04:49, Iteration: 11600, Train Loss: 7.8410e-02, c: 4.1320e-02, d: 3.6945e-02\n",
      "2020/08/02, 05:07:04, Iteration: 11700, Train Loss: 7.8701e-02, c: 4.6070e-02, d: 3.2577e-02\n",
      "2020/08/02, 05:09:20, Iteration: 11800, Train Loss: 7.8378e-02, c: 4.3706e-02, d: 3.4541e-02\n",
      "2020/08/02, 05:11:35, Iteration: 11900, Train Loss: 7.9334e-02, c: 4.3423e-02, d: 3.5858e-02\n",
      "2020/08/02, 05:13:50, Iteration: 12000, Train Loss: 7.9090e-02, c: 4.2456e-02, d: 3.6594e-02\n",
      "2020/08/02, 05:16:06, Iteration: 12100, Train Loss: 7.7402e-02, c: 4.0701e-02, d: 3.6649e-02\n",
      "2020/08/02, 05:18:21, Iteration: 12200, Train Loss: 7.7808e-02, c: 4.3736e-02, d: 3.4043e-02\n",
      "2020/08/02, 05:20:35, Iteration: 12300, Train Loss: 7.7635e-02, c: 4.3491e-02, d: 3.4089e-02\n",
      "2020/08/02, 05:22:51, Iteration: 12400, Train Loss: 7.8614e-02, c: 4.6187e-02, d: 3.2378e-02\n",
      "2020/08/02, 05:25:06, Iteration: 12500, Train Loss: 7.8419e-02, c: 4.2682e-02, d: 3.5696e-02\n",
      "2020/08/02, 05:27:21, Iteration: 12600, Train Loss: 7.7332e-02, c: 4.2703e-02, d: 3.4584e-02\n",
      "2020/08/02, 05:29:36, Iteration: 12700, Train Loss: 7.7978e-02, c: 4.0527e-02, d: 3.7412e-02\n",
      "2020/08/02, 05:31:51, Iteration: 12800, Train Loss: 7.7671e-02, c: 4.2310e-02, d: 3.5337e-02\n",
      "2020/08/02, 05:34:06, Iteration: 12900, Train Loss: 7.7440e-02, c: 4.3426e-02, d: 3.3958e-02\n",
      "2020/08/02, 05:36:21, Iteration: 13000, Train Loss: 7.9747e-02, c: 4.3465e-02, d: 3.6194e-02\n",
      "2020/08/02, 05:38:36, Iteration: 13100, Train Loss: 7.7951e-02, c: 4.2462e-02, d: 3.5273e-02\n",
      "2020/08/02, 05:40:51, Iteration: 13200, Train Loss: 7.8387e-02, c: 4.3185e-02, d: 3.5155e-02\n",
      "2020/08/02, 05:43:06, Iteration: 13300, Train Loss: 7.9396e-02, c: 4.1657e-02, d: 3.7621e-02\n",
      "2020/08/02, 05:45:21, Iteration: 13400, Train Loss: 7.9521e-02, c: 4.5279e-02, d: 3.4213e-02\n",
      "2020/08/02, 05:47:35, Iteration: 13500, Train Loss: 7.7790e-02, c: 4.0410e-02, d: 3.7339e-02\n",
      "2020/08/02, 05:49:51, Iteration: 13600, Train Loss: 7.8665e-02, c: 4.2314e-02, d: 3.6171e-02\n",
      "2020/08/02, 05:52:05, Iteration: 13700, Train Loss: 7.8772e-02, c: 4.7376e-02, d: 3.1299e-02\n",
      "2020/08/02, 05:54:21, Iteration: 13800, Train Loss: 7.7254e-02, c: 4.3112e-02, d: 3.4104e-02\n",
      "2020/08/02, 05:56:36, Iteration: 13900, Train Loss: 7.7689e-02, c: 4.1305e-02, d: 3.6325e-02\n",
      "2020/08/02, 05:58:51, Iteration: 14000, Train Loss: 7.8738e-02, c: 4.1885e-02, d: 3.6740e-02\n",
      "2020/08/02, 06:01:05, Iteration: 14100, Train Loss: 7.8501e-02, c: 4.2178e-02, d: 3.6253e-02\n",
      "2020/08/02, 06:03:19, Iteration: 14200, Train Loss: 7.8035e-02, c: 4.4987e-02, d: 3.2888e-02\n",
      "2020/08/02, 06:05:34, Iteration: 14300, Train Loss: 7.8531e-02, c: 4.1976e-02, d: 3.6529e-02\n",
      "2020/08/02, 06:07:48, Iteration: 14400, Train Loss: 7.8702e-02, c: 4.2344e-02, d: 3.6321e-02\n",
      "2020/08/02, 06:10:02, Iteration: 14500, Train Loss: 7.7483e-02, c: 4.2735e-02, d: 3.4689e-02\n",
      "2020/08/02, 06:12:17, Iteration: 14600, Train Loss: 7.7986e-02, c: 4.2841e-02, d: 3.5091e-02\n",
      "2020/08/02, 06:14:31, Iteration: 14700, Train Loss: 7.8046e-02, c: 4.3714e-02, d: 3.4254e-02\n",
      "2020/08/02, 06:16:46, Iteration: 14800, Train Loss: 7.7333e-02, c: 4.2121e-02, d: 3.5161e-02\n",
      "2020/08/02, 06:19:00, Iteration: 14900, Train Loss: 7.7716e-02, c: 4.2128e-02, d: 3.5540e-02\n",
      "2020/08/02, 06:21:15, Iteration: 15000, Train Loss: 7.8168e-02, c: 4.2825e-02, d: 3.5316e-02\n",
      "2020/08/02, 06:23:30, Iteration: 15100, Train Loss: 7.8287e-02, c: 4.2187e-02, d: 3.6072e-02\n",
      "2020/08/02, 06:25:44, Iteration: 15200, Train Loss: 7.8214e-02, c: 4.2279e-02, d: 3.5877e-02\n",
      "2020/08/02, 06:27:59, Iteration: 15300, Train Loss: 7.7916e-02, c: 4.4590e-02, d: 3.3255e-02\n",
      "2020/08/02, 06:30:13, Iteration: 15400, Train Loss: 7.7179e-02, c: 4.2031e-02, d: 3.5130e-02\n",
      "2020/08/02, 06:32:27, Iteration: 15500, Train Loss: 8.1843e-02, c: 4.4239e-02, d: 3.7548e-02\n",
      "2020/08/02, 06:34:42, Iteration: 15600, Train Loss: 7.8817e-02, c: 4.4058e-02, d: 3.4723e-02\n",
      "2020/08/02, 06:36:57, Iteration: 15700, Train Loss: 7.7502e-02, c: 4.3117e-02, d: 3.4339e-02\n",
      "2020/08/02, 06:39:12, Iteration: 15800, Train Loss: 7.7812e-02, c: 4.1493e-02, d: 3.6279e-02\n",
      "2020/08/02, 06:41:27, Iteration: 15900, Train Loss: 7.7376e-02, c: 4.2780e-02, d: 3.4563e-02\n",
      "2020/08/02, 06:43:41, Iteration: 16000, Train Loss: 7.7556e-02, c: 4.3241e-02, d: 3.4267e-02\n",
      "2020/08/02, 06:45:55, Iteration: 16100, Train Loss: 7.8142e-02, c: 4.4647e-02, d: 3.3426e-02\n",
      "2020/08/02, 06:48:10, Iteration: 16200, Train Loss: 7.8606e-02, c: 4.2159e-02, d: 3.6403e-02\n",
      "2020/08/02, 06:50:24, Iteration: 16300, Train Loss: 7.9575e-02, c: 4.4840e-02, d: 3.4691e-02\n",
      "2020/08/02, 06:52:38, Iteration: 16400, Train Loss: 7.8742e-02, c: 4.2152e-02, d: 3.6502e-02\n",
      "2020/08/02, 06:54:53, Iteration: 16500, Train Loss: 7.7987e-02, c: 4.2067e-02, d: 3.5854e-02\n",
      "2020/08/02, 06:57:07, Iteration: 16600, Train Loss: 7.8474e-02, c: 4.3060e-02, d: 3.5363e-02\n",
      "2020/08/02, 06:59:22, Iteration: 16700, Train Loss: 7.8546e-02, c: 4.2664e-02, d: 3.5846e-02\n",
      "2020/08/02, 07:01:36, Iteration: 16800, Train Loss: 7.7742e-02, c: 4.3839e-02, d: 3.3854e-02\n",
      "2020/08/02, 07:03:51, Iteration: 16900, Train Loss: 7.8045e-02, c: 4.2413e-02, d: 3.5588e-02\n",
      "2020/08/02, 07:06:05, Iteration: 17000, Train Loss: 7.8902e-02, c: 4.1627e-02, d: 3.7183e-02\n",
      "2020/08/02, 07:08:19, Iteration: 17100, Train Loss: 7.7822e-02, c: 4.2491e-02, d: 3.5285e-02\n",
      "2020/08/02, 07:10:34, Iteration: 17200, Train Loss: 7.7530e-02, c: 4.0827e-02, d: 3.6666e-02\n",
      "2020/08/02, 07:12:48, Iteration: 17300, Train Loss: 7.7716e-02, c: 4.5162e-02, d: 3.2466e-02\n",
      "2020/08/02, 07:15:03, Iteration: 17400, Train Loss: 7.9025e-02, c: 4.2414e-02, d: 3.6562e-02\n",
      "2020/08/02, 07:17:17, Iteration: 17500, Train Loss: 7.7887e-02, c: 4.3640e-02, d: 3.4232e-02\n",
      "2020/08/02, 07:19:31, Iteration: 17600, Train Loss: 7.7785e-02, c: 4.4558e-02, d: 3.3167e-02\n",
      "2020/08/02, 07:21:45, Iteration: 17700, Train Loss: 7.7796e-02, c: 4.1465e-02, d: 3.6278e-02\n",
      "2020/08/02, 07:23:59, Iteration: 17800, Train Loss: 7.8060e-02, c: 4.2240e-02, d: 3.5787e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/08/02, 07:26:13, Iteration: 17900, Train Loss: 7.7413e-02, c: 4.3996e-02, d: 3.3374e-02\n",
      "2020/08/02, 07:28:28, Iteration: 18000, Train Loss: 7.8071e-02, c: 4.1859e-02, d: 3.6102e-02\n",
      "2020/08/02, 07:30:42, Iteration: 18100, Train Loss: 7.8712e-02, c: 4.1251e-02, d: 3.7420e-02\n",
      "2020/08/02, 07:32:57, Iteration: 18200, Train Loss: 7.8809e-02, c: 4.1750e-02, d: 3.6982e-02\n",
      "2020/08/02, 07:35:10, Iteration: 18300, Train Loss: 7.8255e-02, c: 4.1018e-02, d: 3.7212e-02\n",
      "2020/08/02, 07:37:25, Iteration: 18400, Train Loss: 7.7918e-02, c: 4.2372e-02, d: 3.5506e-02\n",
      "2020/08/02, 07:39:39, Iteration: 18500, Train Loss: 7.8267e-02, c: 4.0952e-02, d: 3.7284e-02\n",
      "2020/08/02, 07:41:54, Iteration: 18600, Train Loss: 7.7420e-02, c: 4.3765e-02, d: 3.3630e-02\n",
      "2020/08/02, 07:44:08, Iteration: 18700, Train Loss: 7.8157e-02, c: 4.5003e-02, d: 3.3140e-02\n",
      "2020/08/02, 07:46:23, Iteration: 18800, Train Loss: 7.7613e-02, c: 4.0997e-02, d: 3.6552e-02\n",
      "2020/08/02, 07:48:37, Iteration: 18900, Train Loss: 7.7535e-02, c: 4.3312e-02, d: 3.4148e-02\n",
      "2020/08/02, 07:50:52, Iteration: 19000, Train Loss: 7.8879e-02, c: 4.1094e-02, d: 3.7728e-02\n",
      "2020/08/02, 07:53:05, Iteration: 19100, Train Loss: 7.8773e-02, c: 4.2406e-02, d: 3.6337e-02\n",
      "2020/08/02, 07:55:20, Iteration: 19200, Train Loss: 7.7716e-02, c: 4.2496e-02, d: 3.5179e-02\n",
      "2020/08/02, 07:57:35, Iteration: 19300, Train Loss: 7.7278e-02, c: 4.2440e-02, d: 3.4818e-02\n",
      "2020/08/02, 07:59:49, Iteration: 19400, Train Loss: 7.8550e-02, c: 4.1734e-02, d: 3.6789e-02\n",
      "2020/08/02, 08:02:02, Iteration: 19500, Train Loss: 7.8059e-02, c: 4.2509e-02, d: 3.5524e-02\n",
      "2020/08/02, 08:04:16, Iteration: 19600, Train Loss: 7.7718e-02, c: 4.3084e-02, d: 3.4587e-02\n",
      "2020/08/02, 08:06:30, Iteration: 19700, Train Loss: 7.9116e-02, c: 4.4512e-02, d: 3.4572e-02\n",
      "2020/08/02, 08:08:44, Iteration: 19800, Train Loss: 7.8243e-02, c: 4.2810e-02, d: 3.5380e-02\n",
      "2020/08/02, 08:10:58, Iteration: 19900, Train Loss: 7.7676e-02, c: 4.3311e-02, d: 3.4347e-02\n",
      "2020/08/02, 08:13:12, Iteration: 20000, Train Loss: 7.8955e-02, c: 4.5036e-02, d: 3.3877e-02\n",
      "2020/08/02, 08:15:26, Iteration: 20100, Train Loss: 7.9271e-02, c: 4.4758e-02, d: 3.4482e-02\n",
      "2020/08/02, 08:17:41, Iteration: 20200, Train Loss: 7.8685e-02, c: 4.3541e-02, d: 3.5113e-02\n",
      "2020/08/02, 08:19:55, Iteration: 20300, Train Loss: 7.7901e-02, c: 4.5765e-02, d: 3.2089e-02\n",
      "2020/08/02, 08:22:10, Iteration: 20400, Train Loss: 7.8300e-02, c: 4.1563e-02, d: 3.6710e-02\n",
      "2020/08/02, 08:24:25, Iteration: 20500, Train Loss: 7.8326e-02, c: 4.5626e-02, d: 3.2643e-02\n",
      "2020/08/02, 08:26:39, Iteration: 20600, Train Loss: 7.8303e-02, c: 3.9167e-02, d: 3.9098e-02\n",
      "2020/08/02, 08:28:53, Iteration: 20700, Train Loss: 7.9110e-02, c: 4.5019e-02, d: 3.4041e-02\n",
      "2020/08/02, 08:31:06, Iteration: 20800, Train Loss: 7.7377e-02, c: 4.2681e-02, d: 3.4656e-02\n",
      "2020/08/02, 08:33:21, Iteration: 20900, Train Loss: 7.7779e-02, c: 4.1746e-02, d: 3.5973e-02\n",
      "2020/08/02, 08:35:35, Iteration: 21000, Train Loss: 7.7864e-02, c: 4.4485e-02, d: 3.3354e-02\n",
      "2020/08/02, 08:37:49, Iteration: 21100, Train Loss: 7.7938e-02, c: 4.3672e-02, d: 3.4212e-02\n",
      "2020/08/02, 08:40:03, Iteration: 21200, Train Loss: 7.7882e-02, c: 4.1110e-02, d: 3.6707e-02\n",
      "2020/08/02, 08:42:16, Iteration: 21300, Train Loss: 7.8148e-02, c: 4.5544e-02, d: 3.2551e-02\n",
      "2020/08/02, 08:44:30, Iteration: 21400, Train Loss: 7.8419e-02, c: 4.6567e-02, d: 3.1798e-02\n",
      "2020/08/02, 08:46:44, Iteration: 21500, Train Loss: 7.7583e-02, c: 4.3335e-02, d: 3.4228e-02\n",
      "2020/08/02, 08:48:57, Iteration: 21600, Train Loss: 7.7705e-02, c: 4.2766e-02, d: 3.4893e-02\n",
      "2020/08/02, 08:51:11, Iteration: 21700, Train Loss: 7.7814e-02, c: 4.4154e-02, d: 3.3632e-02\n",
      "2020/08/02, 08:53:26, Iteration: 21800, Train Loss: 7.7392e-02, c: 4.3812e-02, d: 3.3550e-02\n",
      "2020/08/02, 08:55:39, Iteration: 21900, Train Loss: 7.7165e-02, c: 4.3823e-02, d: 3.3299e-02\n",
      "2020/08/02, 08:57:53, Iteration: 22000, Train Loss: 7.8024e-02, c: 4.3074e-02, d: 3.4932e-02\n",
      "2020/08/02, 09:00:07, Iteration: 22100, Train Loss: 7.7782e-02, c: 4.2416e-02, d: 3.5339e-02\n",
      "2020/08/02, 09:02:21, Iteration: 22200, Train Loss: 8.0329e-02, c: 4.2564e-02, d: 3.7720e-02\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "start_iteration = 0\n",
    "iterations = 50000\n",
    "print_every = 100\n",
    "save_every = 50000\n",
    "batch_size = {\"dirichlet\": 50, \"bc\": 50, \"collocation\": 20000}\n",
    "weights = {\"c\": 1.0, \"d\": 1.0, \"pbc_d\": 1.0, \"pbc_n\": 1.0}\n",
    "\n",
    "key, *subkeys = random.split(key, 4)\n",
    "Dirichlet = Batch_Generator(subkeys[0], dirichlet, batch_size[\"dirichlet\"])\n",
    "Collocation = Batch_Generator(subkeys[1], collocation, batch_size[\"collocation\"])\n",
    "BC = Batch_Generator(subkeys[2], periodic_bc, batch_size[\"bc\"])\n",
    "params = direct_params\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "opt_state = opt_init(params)\n",
    "hist = {\"iter\": [], \"loss\": []}\n",
    "\n",
    "for iteration in range(start_iteration, start_iteration+iterations+1):\n",
    "\tbatch = {\n",
    "\t\t\"dirichlet\": dataset_Dirichlet(*next(Dirichlet)),\n",
    "\t\t\"collocation\": dataset_Collocation(*next(Collocation)),\n",
    "\t\t\"periodic_bc\": dataset_BC(*next(BC)),\n",
    "\t\t\"weights\": weights\n",
    "\t}\n",
    "\topt_state = step(iteration, opt_state, batch)\n",
    "\tif (iteration-start_iteration) % print_every == 0:\n",
    "\t\tnames = [\"Loss\", \"c\", \"d\"]\n",
    "\t\tparams_ = get_params(opt_state)\n",
    "\t\tlosses = evaluate(params_, batch)\n",
    "\t\tprint(\"{}, Iteration: {}, Train\".format(get_time(), iteration) + \\\n",
    "\t\t\t  ','.join([\" {}: {:.4e}\".format(name, loss) for name, loss in zip(names, losses)]))\n",
    "\t\thist[\"iter\"].append(iteration)\n",
    "\t\thist[\"loss\"].append(losses[0])\n",
    "\tif (iteration-start_iteration) % save_every == 0:\n",
    "\t\tparams_ = np.asarray(get_params(opt_state), dtype = object)\n",
    "\t\tsave_path = \"models/{}/iteration_{}/params.npy\".format(NAME, iteration)\n",
    "\t\tif not os.path.exists(os.path.dirname(save_path)):\n",
    "\t\t\tos.makedirs(os.path.dirname(save_path))\n",
    "\t\tnp.save(save_path, params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

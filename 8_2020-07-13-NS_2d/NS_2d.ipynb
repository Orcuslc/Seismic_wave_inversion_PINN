{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Maziar Raissi\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../Utilities/')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "import time\n",
    "from itertools import product, combinations\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, x, y, t, u, v, layers):\n",
    "        \n",
    "        X = np.concatenate([x, y, t], 1)\n",
    "        \n",
    "        self.lb = X.min(0)\n",
    "        self.ub = X.max(0)\n",
    "                \n",
    "        self.X = X\n",
    "        \n",
    "        self.x = X[:,0:1]\n",
    "        self.y = X[:,1:2]\n",
    "        self.t = X[:,2:3]\n",
    "        \n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        \n",
    "        self.layers = layers\n",
    "        \n",
    "        # Initialize NN\n",
    "        self.weights, self.biases = self.initialize_NN(layers)        \n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.lambda_1 = tf.Variable([0.0], dtype=tf.float32)\n",
    "        self.lambda_2 = tf.Variable([0.0], dtype=tf.float32)\n",
    "        \n",
    "        # tf placeholders and graph\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "        \n",
    "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
    "        self.y_tf = tf.placeholder(tf.float32, shape=[None, self.y.shape[1]])\n",
    "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
    "        \n",
    "        self.u_tf = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n",
    "        self.v_tf = tf.placeholder(tf.float32, shape=[None, self.v.shape[1]])\n",
    "        \n",
    "        self.u_pred, self.v_pred, self.p_pred, self.f_u_pred, self.f_v_pred = self.net_NS(self.x_tf, self.y_tf, self.t_tf)\n",
    "        \n",
    "        self.loss = tf.reduce_sum(tf.square(self.u_tf - self.u_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.v_tf - self.v_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.f_u_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.f_v_pred))\n",
    "                    \n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 50000,\n",
    "                                                                           'maxfun': 50000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})        \n",
    "        \n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)                    \n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initialize_NN(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "        \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        \n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "        \n",
    "    def net_NS(self, x, y, t):\n",
    "        lambda_1 = self.lambda_1\n",
    "        lambda_2 = self.lambda_2\n",
    "        \n",
    "        psi_and_p = self.neural_net(tf.concat([x,y,t], 1), self.weights, self.biases)\n",
    "        psi = psi_and_p[:,0:1]\n",
    "        p = psi_and_p[:,1:2]\n",
    "        \n",
    "        u = tf.gradients(psi, y)[0]\n",
    "        v = -tf.gradients(psi, x)[0]  \n",
    "        \n",
    "        u_t = tf.gradients(u, t)[0]\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_y = tf.gradients(u, y)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        u_yy = tf.gradients(u_y, y)[0]\n",
    "        \n",
    "        v_t = tf.gradients(v, t)[0]\n",
    "        v_x = tf.gradients(v, x)[0]\n",
    "        v_y = tf.gradients(v, y)[0]\n",
    "        v_xx = tf.gradients(v_x, x)[0]\n",
    "        v_yy = tf.gradients(v_y, y)[0]\n",
    "        \n",
    "        p_x = tf.gradients(p, x)[0]\n",
    "        p_y = tf.gradients(p, y)[0]\n",
    "\n",
    "        f_u = u_t + lambda_1*(u*u_x + v*u_y) + p_x - lambda_2*(u_xx + u_yy) \n",
    "        f_v = v_t + lambda_1*(u*v_x + v*v_y) + p_y - lambda_2*(v_xx + v_yy)\n",
    "        \n",
    "        return u, v, p, f_u, f_v\n",
    "    \n",
    "    def callback(self, loss, lambda_1, lambda_2):\n",
    "        print('Loss: %.3e, l1: %.3f, l2: %.5f' % (loss, lambda_1, lambda_2))\n",
    "      \n",
    "    def train(self, nIter): \n",
    "\n",
    "        tf_dict = {self.x_tf: self.x, self.y_tf: self.y, self.t_tf: self.t,\n",
    "                   self.u_tf: self.u, self.v_tf: self.v}\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            \n",
    "            # Print\n",
    "            if it % 500 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                loss_value = self.sess.run(self.loss, tf_dict)\n",
    "                lambda_1_value = self.sess.run(self.lambda_1)\n",
    "                lambda_2_value = self.sess.run(self.lambda_2)\n",
    "                print('It: %d, Loss: %.3e, l1: %.3f, l2: %.5f, Time: %.2f' % \n",
    "                      (it, loss_value, lambda_1_value, lambda_2_value, elapsed))\n",
    "                start_time = time.time()\n",
    "            \n",
    "        self.optimizer.minimize(self.sess,\n",
    "                                feed_dict = tf_dict,\n",
    "                                fetches = [self.loss, self.lambda_1, self.lambda_2],\n",
    "                                loss_callback = self.callback)\n",
    "            \n",
    "    \n",
    "    def predict(self, x_star, y_star, t_star):\n",
    "        \n",
    "        tf_dict = {self.x_tf: x_star, self.y_tf: y_star, self.t_tf: t_star}\n",
    "        \n",
    "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "        v_star = self.sess.run(self.v_pred, tf_dict)\n",
    "        p_star = self.sess.run(self.p_pred, tf_dict)\n",
    "        \n",
    "        return u_star, v_star, p_star\n",
    "\n",
    "def plot_solution(X_star, u_star, index):\n",
    "    \n",
    "    lb = X_star.min(0)\n",
    "    ub = X_star.max(0)\n",
    "    nn = 200\n",
    "    x = np.linspace(lb[0], ub[0], nn)\n",
    "    y = np.linspace(lb[1], ub[1], nn)\n",
    "    X, Y = np.meshgrid(x,y)\n",
    "    \n",
    "    U_star = griddata(X_star, u_star.flatten(), (X, Y), method='cubic')\n",
    "    \n",
    "    plt.figure(index)\n",
    "    plt.pcolor(X,Y,U_star, cmap = 'jet')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    \n",
    "def axisEqual3D(ax):\n",
    "    extents = np.array([getattr(ax, 'get_{}lim'.format(dim))() for dim in 'xyz'])\n",
    "    sz = extents[:,1] - extents[:,0]\n",
    "    centers = np.mean(extents, axis=1)\n",
    "    maxsize = max(abs(sz))\n",
    "    r = maxsize/4\n",
    "    for ctr, dim in zip(centers, 'xyz'):\n",
    "        getattr(ax, 'set_{}lim'.format(dim))(ctr - r, ctr + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "It: 0, Loss: 4.252e+03, l1: -0.001, l2: 0.00100, Time: 9.76\n",
      "It: 500, Loss: 4.759e+02, l1: -0.005, l2: -0.00027, Time: 62.16\n",
      "It: 1000, Loss: 4.682e+02, l1: -0.011, l2: -0.00032, Time: 62.24\n",
      "It: 1500, Loss: 4.659e+02, l1: -0.018, l2: -0.00054, Time: 62.18\n",
      "It: 2000, Loss: 4.611e+02, l1: -0.040, l2: -0.00109, Time: 62.21\n",
      "It: 2500, Loss: 4.550e+02, l1: 0.017, l2: 0.00036, Time: 62.23\n",
      "It: 3000, Loss: 4.500e+02, l1: 0.068, l2: 0.00166, Time: 62.20\n",
      "It: 3500, Loss: 4.405e+02, l1: 0.156, l2: 0.00501, Time: 62.23\n",
      "It: 4000, Loss: 3.171e+02, l1: 0.781, l2: 0.01737, Time: 62.22\n",
      "It: 4500, Loss: 1.060e+02, l1: 0.863, l2: 0.01210, Time: 62.21\n",
      "It: 5000, Loss: 7.764e+01, l1: 0.900, l2: 0.01461, Time: 62.21\n",
      "It: 5500, Loss: 6.121e+01, l1: 0.929, l2: 0.01547, Time: 62.18\n",
      "It: 6000, Loss: 5.115e+01, l1: 0.945, l2: 0.01525, Time: 62.24\n",
      "It: 6500, Loss: 4.385e+01, l1: 0.955, l2: 0.01491, Time: 62.23\n",
      "It: 7000, Loss: 3.771e+01, l1: 0.961, l2: 0.01462, Time: 62.22\n",
      "It: 7500, Loss: 3.285e+01, l1: 0.966, l2: 0.01429, Time: 62.21\n",
      "It: 8000, Loss: 2.937e+01, l1: 0.968, l2: 0.01380, Time: 62.26\n",
      "It: 8500, Loss: 2.812e+01, l1: 0.971, l2: 0.01338, Time: 62.26\n",
      "It: 9000, Loss: 2.432e+01, l1: 0.973, l2: 0.01302, Time: 62.22\n",
      "It: 9500, Loss: 2.253e+01, l1: 0.974, l2: 0.01271, Time: 62.20\n",
      "It: 10000, Loss: 2.107e+01, l1: 0.975, l2: 0.01247, Time: 62.22\n",
      "It: 10500, Loss: 3.095e+01, l1: 0.975, l2: 0.01238, Time: 62.19\n",
      "It: 11000, Loss: 1.884e+01, l1: 0.976, l2: 0.01217, Time: 62.26\n",
      "It: 11500, Loss: 1.793e+01, l1: 0.977, l2: 0.01208, Time: 62.20\n",
      "It: 12000, Loss: 1.750e+01, l1: 0.977, l2: 0.01203, Time: 62.24\n",
      "It: 12500, Loss: 1.641e+01, l1: 0.978, l2: 0.01195, Time: 62.25\n",
      "It: 13000, Loss: 1.735e+01, l1: 0.978, l2: 0.01197, Time: 62.24\n",
      "It: 13500, Loss: 1.523e+01, l1: 0.979, l2: 0.01184, Time: 62.23\n",
      "It: 14000, Loss: 1.449e+01, l1: 0.979, l2: 0.01176, Time: 62.29\n",
      "It: 14500, Loss: 1.391e+01, l1: 0.980, l2: 0.01169, Time: 62.27\n",
      "It: 15000, Loss: 1.335e+01, l1: 0.980, l2: 0.01162, Time: 62.24\n",
      "It: 15500, Loss: 1.283e+01, l1: 0.981, l2: 0.01153, Time: 62.24\n",
      "It: 16000, Loss: 1.237e+01, l1: 0.981, l2: 0.01143, Time: 62.21\n",
      "It: 16500, Loss: 1.205e+01, l1: 0.981, l2: 0.01138, Time: 62.20\n",
      "It: 17000, Loss: 1.148e+01, l1: 0.981, l2: 0.01123, Time: 62.23\n",
      "It: 17500, Loss: 1.103e+01, l1: 0.982, l2: 0.01117, Time: 62.26\n",
      "It: 18000, Loss: 1.065e+01, l1: 0.983, l2: 0.01107, Time: 62.24\n",
      "It: 18500, Loss: 1.024e+01, l1: 0.983, l2: 0.01097, Time: 62.23\n",
      "It: 19000, Loss: 9.896e+00, l1: 0.984, l2: 0.01086, Time: 62.23\n",
      "It: 19500, Loss: 9.637e+00, l1: 0.984, l2: 0.01079, Time: 62.16\n",
      "It: 20000, Loss: 9.173e+00, l1: 0.984, l2: 0.01070, Time: 62.25\n",
      "It: 20500, Loss: 8.798e+00, l1: 0.985, l2: 0.01059, Time: 62.21\n",
      "It: 21000, Loss: 8.460e+00, l1: 0.985, l2: 0.01052, Time: 62.24\n",
      "It: 21500, Loss: 8.219e+00, l1: 0.986, l2: 0.01044, Time: 62.22\n",
      "It: 22000, Loss: 8.063e+00, l1: 0.985, l2: 0.01034, Time: 62.21\n",
      "It: 22500, Loss: 7.585e+00, l1: 0.986, l2: 0.01033, Time: 62.28\n",
      "It: 23000, Loss: 7.455e+00, l1: 0.986, l2: 0.01030, Time: 62.24\n",
      "It: 23500, Loss: 7.603e+00, l1: 0.987, l2: 0.01031, Time: 62.24\n",
      "It: 24000, Loss: 6.806e+00, l1: 0.987, l2: 0.01024, Time: 62.27\n",
      "It: 24500, Loss: 6.713e+00, l1: 0.987, l2: 0.01025, Time: 62.22\n",
      "It: 25000, Loss: 6.438e+00, l1: 0.988, l2: 0.01022, Time: 62.24\n",
      "It: 25500, Loss: 6.213e+00, l1: 0.988, l2: 0.01021, Time: 62.27\n",
      "It: 26000, Loss: 6.555e+00, l1: 0.988, l2: 0.01021, Time: 62.21\n",
      "It: 26500, Loss: 6.115e+00, l1: 0.988, l2: 0.01020, Time: 62.24\n",
      "It: 27000, Loss: 5.752e+00, l1: 0.989, l2: 0.01019, Time: 62.24\n",
      "It: 27500, Loss: 5.769e+00, l1: 0.989, l2: 0.01022, Time: 62.27\n",
      "It: 28000, Loss: 6.187e+00, l1: 0.989, l2: 0.01022, Time: 62.27\n",
      "It: 28500, Loss: 5.388e+00, l1: 0.990, l2: 0.01020, Time: 62.27\n",
      "It: 29000, Loss: 6.166e+00, l1: 0.990, l2: 0.01021, Time: 62.30\n",
      "It: 29500, Loss: 5.196e+00, l1: 0.990, l2: 0.01019, Time: 62.26\n",
      "It: 30000, Loss: 5.076e+00, l1: 0.990, l2: 0.01021, Time: 62.34\n",
      "It: 30500, Loss: 6.353e+00, l1: 0.990, l2: 0.01014, Time: 62.30\n",
      "It: 31000, Loss: 4.903e+00, l1: 0.991, l2: 0.01021, Time: 62.25\n",
      "It: 31500, Loss: 4.828e+00, l1: 0.991, l2: 0.01021, Time: 62.23\n",
      "It: 32000, Loss: 4.730e+00, l1: 0.991, l2: 0.01021, Time: 62.25\n",
      "It: 32500, Loss: 1.181e+01, l1: 0.991, l2: 0.01034, Time: 62.20\n",
      "It: 33000, Loss: 4.569e+00, l1: 0.991, l2: 0.01023, Time: 62.22\n",
      "It: 33500, Loss: 5.293e+00, l1: 0.992, l2: 0.01020, Time: 62.26\n",
      "It: 34000, Loss: 4.544e+00, l1: 0.992, l2: 0.01022, Time: 62.21\n",
      "It: 34500, Loss: 4.383e+00, l1: 0.992, l2: 0.01024, Time: 62.19\n",
      "It: 35000, Loss: 4.422e+00, l1: 0.992, l2: 0.01025, Time: 62.19\n",
      "It: 35500, Loss: 4.301e+00, l1: 0.992, l2: 0.01024, Time: 62.18\n",
      "It: 36000, Loss: 4.641e+00, l1: 0.992, l2: 0.01029, Time: 62.18\n",
      "It: 36500, Loss: 5.143e+00, l1: 0.992, l2: 0.01031, Time: 62.18\n",
      "It: 37000, Loss: 4.068e+00, l1: 0.993, l2: 0.01025, Time: 62.20\n",
      "It: 37500, Loss: 5.051e+00, l1: 0.992, l2: 0.01023, Time: 62.22\n",
      "It: 38000, Loss: 5.184e+00, l1: 0.993, l2: 0.01020, Time: 62.25\n",
      "It: 38500, Loss: 4.002e+00, l1: 0.993, l2: 0.01027, Time: 62.27\n",
      "It: 39000, Loss: 3.863e+00, l1: 0.993, l2: 0.01028, Time: 62.22\n",
      "It: 39500, Loss: 4.928e+00, l1: 0.993, l2: 0.01023, Time: 62.31\n",
      "It: 40000, Loss: 3.823e+00, l1: 0.993, l2: 0.01031, Time: 62.28\n",
      "It: 40500, Loss: 3.851e+00, l1: 0.993, l2: 0.01029, Time: 62.20\n",
      "It: 41000, Loss: 4.178e+00, l1: 0.993, l2: 0.01034, Time: 62.25\n",
      "It: 41500, Loss: 3.650e+00, l1: 0.993, l2: 0.01030, Time: 62.28\n",
      "It: 42000, Loss: 3.634e+00, l1: 0.993, l2: 0.01033, Time: 62.27\n",
      "It: 42500, Loss: 3.552e+00, l1: 0.994, l2: 0.01031, Time: 62.28\n",
      "It: 43000, Loss: 3.853e+00, l1: 0.994, l2: 0.01034, Time: 62.29\n",
      "It: 43500, Loss: 3.524e+00, l1: 0.994, l2: 0.01031, Time: 62.25\n",
      "It: 44000, Loss: 3.430e+00, l1: 0.994, l2: 0.01033, Time: 62.32\n",
      "It: 44500, Loss: 3.400e+00, l1: 0.994, l2: 0.01033, Time: 62.28\n",
      "It: 45000, Loss: 3.561e+00, l1: 0.994, l2: 0.01036, Time: 62.28\n",
      "It: 45500, Loss: 3.707e+00, l1: 0.994, l2: 0.01037, Time: 62.26\n",
      "It: 46000, Loss: 3.298e+00, l1: 0.994, l2: 0.01035, Time: 62.27\n",
      "It: 46500, Loss: 3.265e+00, l1: 0.994, l2: 0.01035, Time: 62.30\n",
      "It: 47000, Loss: 3.287e+00, l1: 0.994, l2: 0.01035, Time: 62.30\n",
      "It: 47500, Loss: 3.415e+00, l1: 0.994, l2: 0.01036, Time: 62.28\n",
      "It: 48000, Loss: 4.681e+00, l1: 0.994, l2: 0.01041, Time: 62.24\n",
      "It: 48500, Loss: 3.168e+00, l1: 0.994, l2: 0.01037, Time: 62.28\n",
      "It: 49000, Loss: 3.214e+00, l1: 0.994, l2: 0.01038, Time: 62.23\n",
      "It: 49500, Loss: 5.007e+00, l1: 0.994, l2: 0.01030, Time: 62.33\n",
      "It: 50000, Loss: 3.246e+00, l1: 0.994, l2: 0.01036, Time: 62.29\n",
      "It: 50500, Loss: 3.600e+00, l1: 0.994, l2: 0.01033, Time: 62.33\n",
      "It: 51000, Loss: 2.969e+00, l1: 0.994, l2: 0.01036, Time: 62.31\n",
      "It: 51500, Loss: 3.024e+00, l1: 0.994, l2: 0.01039, Time: 62.27\n",
      "It: 52000, Loss: 2.915e+00, l1: 0.994, l2: 0.01037, Time: 62.33\n",
      "It: 52500, Loss: 5.620e+00, l1: 0.995, l2: 0.01027, Time: 62.29\n",
      "It: 53000, Loss: 3.570e+00, l1: 0.994, l2: 0.01041, Time: 62.30\n",
      "It: 53500, Loss: 2.830e+00, l1: 0.995, l2: 0.01037, Time: 62.28\n",
      "It: 54000, Loss: 3.129e+00, l1: 0.994, l2: 0.01040, Time: 62.29\n",
      "It: 54500, Loss: 2.775e+00, l1: 0.995, l2: 0.01036, Time: 62.28\n",
      "It: 55000, Loss: 2.760e+00, l1: 0.995, l2: 0.01037, Time: 62.29\n",
      "It: 55500, Loss: 2.739e+00, l1: 0.995, l2: 0.01037, Time: 62.32\n",
      "It: 56000, Loss: 2.823e+00, l1: 0.995, l2: 0.01035, Time: 62.26\n",
      "It: 56500, Loss: 3.469e+00, l1: 0.995, l2: 0.01043, Time: 62.29\n",
      "It: 57000, Loss: 2.651e+00, l1: 0.995, l2: 0.01036, Time: 62.33\n",
      "It: 57500, Loss: 2.627e+00, l1: 0.995, l2: 0.01036, Time: 62.33\n",
      "It: 58000, Loss: 2.731e+00, l1: 0.995, l2: 0.01038, Time: 62.36\n",
      "It: 58500, Loss: 2.582e+00, l1: 0.995, l2: 0.01036, Time: 62.27\n",
      "It: 59000, Loss: 2.640e+00, l1: 0.995, l2: 0.01038, Time: 62.25\n",
      "It: 59500, Loss: 2.536e+00, l1: 0.995, l2: 0.01035, Time: 62.29\n",
      "It: 60000, Loss: 2.515e+00, l1: 0.995, l2: 0.01035, Time: 62.35\n",
      "It: 60500, Loss: 2.978e+00, l1: 0.995, l2: 0.01042, Time: 62.30\n",
      "It: 61000, Loss: 2.470e+00, l1: 0.995, l2: 0.01035, Time: 62.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 61500, Loss: 2.458e+00, l1: 0.995, l2: 0.01035, Time: 62.33\n",
      "It: 62000, Loss: 2.577e+00, l1: 0.995, l2: 0.01034, Time: 62.27\n",
      "It: 62500, Loss: 2.412e+00, l1: 0.995, l2: 0.01034, Time: 62.32\n",
      "It: 63000, Loss: 2.391e+00, l1: 0.995, l2: 0.01034, Time: 62.32\n",
      "It: 63500, Loss: 2.375e+00, l1: 0.995, l2: 0.01034, Time: 62.33\n",
      "It: 64000, Loss: 2.439e+00, l1: 0.995, l2: 0.01035, Time: 62.28\n",
      "It: 64500, Loss: 2.427e+00, l1: 0.995, l2: 0.01034, Time: 62.27\n",
      "It: 65000, Loss: 3.003e+00, l1: 0.995, l2: 0.01038, Time: 62.26\n",
      "It: 65500, Loss: 2.291e+00, l1: 0.995, l2: 0.01033, Time: 62.26\n",
      "It: 66000, Loss: 6.663e+00, l1: 0.995, l2: 0.01020, Time: 62.27\n",
      "It: 66500, Loss: 2.255e+00, l1: 0.995, l2: 0.01032, Time: 62.27\n",
      "It: 67000, Loss: 2.250e+00, l1: 0.995, l2: 0.01033, Time: 62.27\n",
      "It: 67500, Loss: 2.226e+00, l1: 0.995, l2: 0.01032, Time: 62.29\n",
      "It: 68000, Loss: 2.242e+00, l1: 0.995, l2: 0.01034, Time: 62.35\n",
      "It: 68500, Loss: 2.202e+00, l1: 0.995, l2: 0.01032, Time: 62.26\n",
      "It: 69000, Loss: 2.581e+00, l1: 0.995, l2: 0.01028, Time: 62.30\n",
      "It: 69500, Loss: 2.188e+00, l1: 0.995, l2: 0.01030, Time: 62.31\n",
      "It: 70000, Loss: 2.512e+00, l1: 0.995, l2: 0.01027, Time: 62.31\n",
      "It: 70500, Loss: 2.236e+00, l1: 0.995, l2: 0.01026, Time: 62.28\n",
      "It: 71000, Loss: 2.513e+00, l1: 0.995, l2: 0.01033, Time: 62.30\n",
      "It: 71500, Loss: 2.122e+00, l1: 0.995, l2: 0.01031, Time: 62.29\n",
      "It: 72000, Loss: 2.078e+00, l1: 0.995, l2: 0.01030, Time: 62.30\n",
      "It: 72500, Loss: 2.357e+00, l1: 0.995, l2: 0.01027, Time: 62.31\n",
      "It: 73000, Loss: 2.045e+00, l1: 0.995, l2: 0.01029, Time: 62.32\n",
      "It: 73500, Loss: 2.031e+00, l1: 0.996, l2: 0.01029, Time: 62.28\n",
      "It: 74000, Loss: 2.009e+00, l1: 0.996, l2: 0.01029, Time: 62.33\n",
      "It: 74500, Loss: 2.003e+00, l1: 0.996, l2: 0.01029, Time: 62.32\n",
      "It: 75000, Loss: 2.038e+00, l1: 0.995, l2: 0.01031, Time: 62.34\n",
      "It: 75500, Loss: 1.963e+00, l1: 0.996, l2: 0.01029, Time: 62.30\n",
      "It: 76000, Loss: 4.124e+00, l1: 0.996, l2: 0.01038, Time: 62.29\n",
      "It: 76500, Loss: 1.960e+00, l1: 0.996, l2: 0.01030, Time: 62.29\n",
      "It: 77000, Loss: 2.052e+00, l1: 0.995, l2: 0.01029, Time: 62.35\n",
      "It: 77500, Loss: 1.941e+00, l1: 0.996, l2: 0.01029, Time: 62.32\n",
      "It: 78000, Loss: 2.029e+00, l1: 0.996, l2: 0.01026, Time: 62.29\n",
      "It: 78500, Loss: 1.905e+00, l1: 0.995, l2: 0.01027, Time: 62.31\n",
      "It: 79000, Loss: 1.881e+00, l1: 0.996, l2: 0.01029, Time: 62.28\n",
      "It: 79500, Loss: 2.192e+00, l1: 0.996, l2: 0.01030, Time: 62.31\n",
      "It: 80000, Loss: 1.850e+00, l1: 0.996, l2: 0.01029, Time: 62.33\n",
      "It: 80500, Loss: 1.830e+00, l1: 0.996, l2: 0.01028, Time: 62.28\n",
      "It: 81000, Loss: 1.993e+00, l1: 0.996, l2: 0.01026, Time: 62.23\n",
      "It: 81500, Loss: 2.456e+00, l1: 0.996, l2: 0.01036, Time: 62.31\n",
      "It: 82000, Loss: 1.817e+00, l1: 0.996, l2: 0.01029, Time: 62.29\n",
      "It: 82500, Loss: 2.233e+00, l1: 0.996, l2: 0.01033, Time: 62.29\n",
      "It: 83000, Loss: 2.549e+00, l1: 0.996, l2: 0.01034, Time: 62.29\n",
      "It: 83500, Loss: 1.767e+00, l1: 0.996, l2: 0.01029, Time: 62.33\n",
      "It: 84000, Loss: 1.745e+00, l1: 0.996, l2: 0.01028, Time: 62.31\n",
      "It: 84500, Loss: 1.748e+00, l1: 0.996, l2: 0.01028, Time: 62.31\n",
      "It: 85000, Loss: 1.722e+00, l1: 0.996, l2: 0.01029, Time: 62.27\n",
      "It: 85500, Loss: 1.755e+00, l1: 0.996, l2: 0.01028, Time: 62.24\n",
      "It: 86000, Loss: 1.726e+00, l1: 0.996, l2: 0.01028, Time: 62.27\n",
      "It: 86500, Loss: 2.723e+00, l1: 0.996, l2: 0.01034, Time: 62.29\n",
      "It: 87000, Loss: 1.867e+00, l1: 0.996, l2: 0.01031, Time: 62.29\n",
      "It: 87500, Loss: 1.668e+00, l1: 0.996, l2: 0.01029, Time: 62.28\n",
      "It: 88000, Loss: 2.784e+00, l1: 0.996, l2: 0.01035, Time: 62.26\n",
      "It: 88500, Loss: 2.161e+00, l1: 0.996, l2: 0.01033, Time: 62.29\n",
      "It: 89000, Loss: 1.761e+00, l1: 0.996, l2: 0.01027, Time: 62.26\n",
      "It: 89500, Loss: 1.626e+00, l1: 0.996, l2: 0.01029, Time: 62.30\n",
      "It: 90000, Loss: 1.745e+00, l1: 0.996, l2: 0.01030, Time: 62.29\n",
      "It: 90500, Loss: 2.881e+00, l1: 0.996, l2: 0.01022, Time: 62.28\n",
      "It: 91000, Loss: 2.225e+00, l1: 0.996, l2: 0.01026, Time: 62.30\n",
      "It: 91500, Loss: 1.586e+00, l1: 0.996, l2: 0.01029, Time: 62.28\n",
      "It: 92000, Loss: 1.629e+00, l1: 0.996, l2: 0.01029, Time: 62.31\n",
      "It: 92500, Loss: 1.738e+00, l1: 0.996, l2: 0.01032, Time: 62.30\n",
      "It: 93000, Loss: 1.556e+00, l1: 0.996, l2: 0.01030, Time: 62.31\n",
      "It: 93500, Loss: 1.577e+00, l1: 0.996, l2: 0.01029, Time: 62.35\n",
      "It: 94000, Loss: 2.120e+00, l1: 0.996, l2: 0.01025, Time: 62.31\n",
      "It: 94500, Loss: 1.565e+00, l1: 0.996, l2: 0.01030, Time: 62.35\n",
      "It: 95000, Loss: 1.588e+00, l1: 0.996, l2: 0.01033, Time: 62.30\n",
      "It: 95500, Loss: 1.596e+00, l1: 0.996, l2: 0.01027, Time: 62.31\n",
      "It: 96000, Loss: 1.801e+00, l1: 0.996, l2: 0.01029, Time: 62.30\n",
      "It: 96500, Loss: 1.607e+00, l1: 0.996, l2: 0.01028, Time: 62.31\n",
      "It: 97000, Loss: 2.369e+00, l1: 0.996, l2: 0.01022, Time: 62.29\n",
      "It: 97500, Loss: 2.742e+00, l1: 0.996, l2: 0.01029, Time: 62.36\n",
      "It: 98000, Loss: 1.489e+00, l1: 0.996, l2: 0.01030, Time: 62.32\n",
      "It: 98500, Loss: 1.472e+00, l1: 0.996, l2: 0.01030, Time: 62.31\n",
      "It: 99000, Loss: 1.540e+00, l1: 0.997, l2: 0.01029, Time: 62.33\n",
      "It: 99500, Loss: 1.451e+00, l1: 0.997, l2: 0.01031, Time: 62.32\n",
      "It: 100000, Loss: 1.979e+00, l1: 0.996, l2: 0.01032, Time: 62.32\n",
      "It: 100500, Loss: 1.448e+00, l1: 0.997, l2: 0.01031, Time: 62.36\n",
      "It: 101000, Loss: 1.491e+00, l1: 0.996, l2: 0.01034, Time: 62.35\n",
      "It: 101500, Loss: 1.422e+00, l1: 0.997, l2: 0.01031, Time: 62.31\n",
      "It: 102000, Loss: 1.414e+00, l1: 0.997, l2: 0.01031, Time: 62.32\n",
      "It: 102500, Loss: 1.405e+00, l1: 0.997, l2: 0.01031, Time: 62.28\n",
      "It: 103000, Loss: 1.443e+00, l1: 0.996, l2: 0.01034, Time: 62.32\n",
      "It: 103500, Loss: 1.466e+00, l1: 0.997, l2: 0.01033, Time: 62.32\n",
      "It: 104000, Loss: 2.018e+00, l1: 0.997, l2: 0.01028, Time: 62.29\n",
      "It: 104500, Loss: 1.624e+00, l1: 0.996, l2: 0.01030, Time: 62.30\n",
      "It: 105000, Loss: 1.919e+00, l1: 0.997, l2: 0.01033, Time: 62.34\n",
      "It: 105500, Loss: 1.408e+00, l1: 0.997, l2: 0.01030, Time: 62.34\n",
      "It: 106000, Loss: 1.366e+00, l1: 0.997, l2: 0.01032, Time: 62.30\n",
      "It: 106500, Loss: 1.356e+00, l1: 0.997, l2: 0.01032, Time: 62.31\n",
      "It: 107000, Loss: 1.360e+00, l1: 0.997, l2: 0.01033, Time: 62.32\n",
      "It: 107500, Loss: 2.759e+00, l1: 0.997, l2: 0.01023, Time: 62.32\n",
      "It: 108000, Loss: 1.745e+00, l1: 0.997, l2: 0.01037, Time: 62.32\n",
      "It: 108500, Loss: 1.349e+00, l1: 0.997, l2: 0.01033, Time: 62.33\n",
      "It: 109000, Loss: 1.368e+00, l1: 0.997, l2: 0.01030, Time: 62.34\n",
      "It: 109500, Loss: 1.602e+00, l1: 0.997, l2: 0.01035, Time: 62.28\n",
      "It: 110000, Loss: 1.323e+00, l1: 0.997, l2: 0.01031, Time: 62.30\n",
      "It: 110500, Loss: 1.449e+00, l1: 0.997, l2: 0.01030, Time: 62.31\n",
      "It: 111000, Loss: 1.312e+00, l1: 0.997, l2: 0.01032, Time: 62.32\n",
      "It: 111500, Loss: 1.298e+00, l1: 0.997, l2: 0.01032, Time: 62.23\n",
      "It: 112000, Loss: 1.720e+00, l1: 0.997, l2: 0.01036, Time: 62.35\n",
      "It: 112500, Loss: 1.283e+00, l1: 0.997, l2: 0.01033, Time: 62.27\n",
      "It: 113000, Loss: 1.320e+00, l1: 0.997, l2: 0.01033, Time: 62.28\n",
      "It: 113500, Loss: 1.283e+00, l1: 0.997, l2: 0.01032, Time: 62.29\n",
      "It: 114000, Loss: 1.266e+00, l1: 0.997, l2: 0.01032, Time: 62.27\n",
      "It: 114500, Loss: 1.260e+00, l1: 0.997, l2: 0.01033, Time: 62.25\n",
      "It: 115000, Loss: 1.390e+00, l1: 0.997, l2: 0.01036, Time: 62.25\n",
      "It: 115500, Loss: 1.259e+00, l1: 0.997, l2: 0.01032, Time: 62.33\n",
      "It: 116000, Loss: 1.248e+00, l1: 0.997, l2: 0.01032, Time: 62.28\n",
      "It: 116500, Loss: 1.294e+00, l1: 0.997, l2: 0.01033, Time: 62.32\n",
      "It: 117000, Loss: 1.248e+00, l1: 0.997, l2: 0.01033, Time: 62.31\n",
      "It: 117500, Loss: 1.251e+00, l1: 0.997, l2: 0.01033, Time: 62.34\n",
      "It: 118000, Loss: 1.236e+00, l1: 0.997, l2: 0.01033, Time: 62.28\n",
      "It: 118500, Loss: 2.090e+00, l1: 0.997, l2: 0.01028, Time: 62.34\n",
      "It: 119000, Loss: 1.216e+00, l1: 0.997, l2: 0.01033, Time: 62.34\n",
      "It: 119500, Loss: 1.213e+00, l1: 0.997, l2: 0.01034, Time: 62.29\n",
      "It: 120000, Loss: 1.237e+00, l1: 0.997, l2: 0.01033, Time: 62.26\n",
      "It: 120500, Loss: 1.354e+00, l1: 0.997, l2: 0.01037, Time: 62.28\n",
      "It: 121000, Loss: 1.212e+00, l1: 0.997, l2: 0.01034, Time: 62.30\n",
      "It: 121500, Loss: 1.265e+00, l1: 0.997, l2: 0.01036, Time: 62.32\n",
      "It: 122000, Loss: 1.193e+00, l1: 0.997, l2: 0.01034, Time: 62.33\n",
      "It: 122500, Loss: 1.209e+00, l1: 0.997, l2: 0.01034, Time: 62.27\n",
      "It: 123000, Loss: 1.198e+00, l1: 0.997, l2: 0.01034, Time: 62.31\n",
      "It: 123500, Loss: 1.379e+00, l1: 0.997, l2: 0.01037, Time: 62.28\n",
      "It: 124000, Loss: 1.211e+00, l1: 0.997, l2: 0.01034, Time: 62.29\n",
      "It: 124500, Loss: 1.167e+00, l1: 0.997, l2: 0.01034, Time: 62.29\n",
      "It: 125000, Loss: 1.208e+00, l1: 0.997, l2: 0.01032, Time: 62.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 125500, Loss: 1.201e+00, l1: 0.997, l2: 0.01034, Time: 62.27\n",
      "It: 126000, Loss: 1.157e+00, l1: 0.997, l2: 0.01034, Time: 62.31\n",
      "It: 126500, Loss: 1.180e+00, l1: 0.997, l2: 0.01035, Time: 62.28\n",
      "It: 127000, Loss: 1.533e+00, l1: 0.997, l2: 0.01040, Time: 62.26\n",
      "It: 127500, Loss: 1.929e+00, l1: 0.997, l2: 0.01037, Time: 62.32\n",
      "It: 128000, Loss: 1.961e+00, l1: 0.997, l2: 0.01043, Time: 62.28\n",
      "It: 128500, Loss: 1.135e+00, l1: 0.997, l2: 0.01034, Time: 62.26\n",
      "It: 129000, Loss: 1.130e+00, l1: 0.997, l2: 0.01035, Time: 62.24\n",
      "It: 129500, Loss: 1.143e+00, l1: 0.997, l2: 0.01034, Time: 62.28\n",
      "It: 130000, Loss: 1.127e+00, l1: 0.997, l2: 0.01034, Time: 62.25\n",
      "It: 130500, Loss: 1.119e+00, l1: 0.997, l2: 0.01035, Time: 62.26\n",
      "It: 131000, Loss: 1.119e+00, l1: 0.997, l2: 0.01035, Time: 62.26\n",
      "It: 131500, Loss: 1.131e+00, l1: 0.997, l2: 0.01035, Time: 62.26\n",
      "It: 132000, Loss: 1.434e+00, l1: 0.997, l2: 0.01044, Time: 62.24\n",
      "It: 132500, Loss: 1.112e+00, l1: 0.997, l2: 0.01036, Time: 62.22\n",
      "It: 133000, Loss: 1.157e+00, l1: 0.997, l2: 0.01034, Time: 62.28\n",
      "It: 133500, Loss: 1.104e+00, l1: 0.997, l2: 0.01035, Time: 62.23\n",
      "It: 134000, Loss: 1.133e+00, l1: 0.997, l2: 0.01037, Time: 62.24\n",
      "It: 134500, Loss: 1.137e+00, l1: 0.997, l2: 0.01039, Time: 62.29\n",
      "It: 135000, Loss: 1.085e+00, l1: 0.997, l2: 0.01036, Time: 62.23\n",
      "It: 135500, Loss: 1.505e+00, l1: 0.997, l2: 0.01041, Time: 62.27\n",
      "It: 136000, Loss: 1.107e+00, l1: 0.997, l2: 0.01038, Time: 62.26\n",
      "It: 136500, Loss: 1.117e+00, l1: 0.997, l2: 0.01038, Time: 62.29\n",
      "It: 137000, Loss: 1.073e+00, l1: 0.997, l2: 0.01036, Time: 62.28\n",
      "It: 137500, Loss: 1.073e+00, l1: 0.997, l2: 0.01037, Time: 62.30\n",
      "It: 138000, Loss: 1.149e+00, l1: 0.997, l2: 0.01035, Time: 62.25\n",
      "It: 138500, Loss: 1.069e+00, l1: 0.997, l2: 0.01035, Time: 62.24\n",
      "It: 139000, Loss: 1.059e+00, l1: 0.997, l2: 0.01036, Time: 62.31\n",
      "It: 139500, Loss: 1.117e+00, l1: 0.997, l2: 0.01035, Time: 62.26\n",
      "It: 140000, Loss: 2.381e+00, l1: 0.997, l2: 0.01046, Time: 62.22\n",
      "It: 140500, Loss: 1.181e+00, l1: 0.997, l2: 0.01034, Time: 62.27\n",
      "It: 141000, Loss: 1.098e+00, l1: 0.997, l2: 0.01036, Time: 62.24\n",
      "It: 141500, Loss: 1.113e+00, l1: 0.997, l2: 0.01037, Time: 62.24\n",
      "It: 142000, Loss: 1.616e+00, l1: 0.997, l2: 0.01041, Time: 62.22\n",
      "It: 142500, Loss: 1.036e+00, l1: 0.997, l2: 0.01037, Time: 62.23\n",
      "It: 143000, Loss: 1.030e+00, l1: 0.997, l2: 0.01037, Time: 62.24\n",
      "It: 143500, Loss: 1.367e+00, l1: 0.997, l2: 0.01041, Time: 62.25\n",
      "It: 144000, Loss: 1.026e+00, l1: 0.997, l2: 0.01037, Time: 62.28\n",
      "It: 144500, Loss: 1.040e+00, l1: 0.997, l2: 0.01038, Time: 62.24\n",
      "It: 145000, Loss: 1.064e+00, l1: 0.997, l2: 0.01035, Time: 62.29\n",
      "It: 145500, Loss: 1.154e+00, l1: 0.997, l2: 0.01035, Time: 62.23\n",
      "It: 146000, Loss: 1.054e+00, l1: 0.997, l2: 0.01038, Time: 62.25\n",
      "It: 146500, Loss: 1.182e+00, l1: 0.997, l2: 0.01035, Time: 62.28\n",
      "It: 147000, Loss: 1.018e+00, l1: 0.997, l2: 0.01039, Time: 62.26\n",
      "It: 147500, Loss: 1.201e+00, l1: 0.997, l2: 0.01037, Time: 62.23\n",
      "It: 148000, Loss: 1.072e+00, l1: 0.997, l2: 0.01038, Time: 62.26\n",
      "It: 148500, Loss: 1.526e+00, l1: 0.997, l2: 0.01043, Time: 62.24\n",
      "It: 149000, Loss: 9.942e-01, l1: 0.997, l2: 0.01038, Time: 62.19\n",
      "It: 149500, Loss: 1.482e+00, l1: 0.997, l2: 0.01038, Time: 62.26\n",
      "It: 150000, Loss: 9.984e-01, l1: 0.997, l2: 0.01037, Time: 62.24\n",
      "It: 150500, Loss: 1.883e+00, l1: 0.997, l2: 0.01047, Time: 62.26\n",
      "It: 151000, Loss: 9.808e-01, l1: 0.997, l2: 0.01038, Time: 62.24\n",
      "It: 151500, Loss: 9.853e-01, l1: 0.997, l2: 0.01039, Time: 62.26\n",
      "It: 152000, Loss: 1.069e+00, l1: 0.997, l2: 0.01043, Time: 62.27\n",
      "It: 152500, Loss: 9.734e-01, l1: 0.997, l2: 0.01038, Time: 62.28\n",
      "It: 153000, Loss: 1.268e+00, l1: 0.997, l2: 0.01040, Time: 62.23\n",
      "It: 153500, Loss: 9.847e-01, l1: 0.997, l2: 0.01039, Time: 62.28\n",
      "It: 154000, Loss: 9.662e-01, l1: 0.997, l2: 0.01039, Time: 62.27\n",
      "It: 154500, Loss: 1.058e+00, l1: 0.997, l2: 0.01038, Time: 62.22\n",
      "It: 155000, Loss: 9.625e-01, l1: 0.997, l2: 0.01039, Time: 62.31\n",
      "It: 155500, Loss: 1.585e+00, l1: 0.997, l2: 0.01046, Time: 62.32\n",
      "It: 156000, Loss: 9.524e-01, l1: 0.997, l2: 0.01039, Time: 62.29\n",
      "It: 156500, Loss: 9.573e-01, l1: 0.997, l2: 0.01039, Time: 62.29\n",
      "It: 157000, Loss: 9.527e-01, l1: 0.997, l2: 0.01039, Time: 62.26\n",
      "It: 157500, Loss: 9.464e-01, l1: 0.997, l2: 0.01039, Time: 62.25\n",
      "It: 158000, Loss: 9.548e-01, l1: 0.997, l2: 0.01039, Time: 62.24\n",
      "It: 158500, Loss: 9.860e-01, l1: 0.997, l2: 0.01040, Time: 62.28\n",
      "It: 159000, Loss: 9.560e-01, l1: 0.997, l2: 0.01039, Time: 62.31\n",
      "It: 159500, Loss: 9.345e-01, l1: 0.998, l2: 0.01039, Time: 62.30\n",
      "It: 160000, Loss: 1.029e+00, l1: 0.997, l2: 0.01037, Time: 62.29\n",
      "It: 160500, Loss: 1.081e+00, l1: 0.997, l2: 0.01038, Time: 62.26\n",
      "It: 161000, Loss: 1.094e+00, l1: 0.997, l2: 0.01042, Time: 62.28\n",
      "It: 161500, Loss: 9.414e-01, l1: 0.997, l2: 0.01038, Time: 62.28\n",
      "It: 162000, Loss: 9.862e-01, l1: 0.998, l2: 0.01039, Time: 62.28\n",
      "It: 162500, Loss: 9.224e-01, l1: 0.998, l2: 0.01039, Time: 62.23\n",
      "It: 163000, Loss: 9.181e-01, l1: 0.998, l2: 0.01040, Time: 62.29\n",
      "It: 163500, Loss: 2.629e+00, l1: 0.998, l2: 0.01029, Time: 62.29\n",
      "It: 164000, Loss: 9.223e-01, l1: 0.998, l2: 0.01040, Time: 62.29\n",
      "It: 164500, Loss: 1.064e+00, l1: 0.997, l2: 0.01038, Time: 62.32\n",
      "It: 165000, Loss: 9.065e-01, l1: 0.998, l2: 0.01040, Time: 62.29\n",
      "It: 165500, Loss: 9.030e-01, l1: 0.998, l2: 0.01040, Time: 62.24\n",
      "It: 166000, Loss: 9.006e-01, l1: 0.998, l2: 0.01040, Time: 62.29\n",
      "It: 166500, Loss: 9.720e-01, l1: 0.997, l2: 0.01036, Time: 62.26\n",
      "It: 167000, Loss: 1.192e+00, l1: 0.998, l2: 0.01036, Time: 62.23\n",
      "It: 167500, Loss: 9.000e-01, l1: 0.998, l2: 0.01039, Time: 62.29\n",
      "It: 168000, Loss: 8.972e-01, l1: 0.998, l2: 0.01040, Time: 62.27\n",
      "It: 168500, Loss: 8.899e-01, l1: 0.998, l2: 0.01041, Time: 62.28\n",
      "It: 169000, Loss: 8.868e-01, l1: 0.998, l2: 0.01040, Time: 62.25\n",
      "It: 169500, Loss: 8.847e-01, l1: 0.998, l2: 0.01040, Time: 62.23\n",
      "It: 170000, Loss: 9.846e-01, l1: 0.997, l2: 0.01040, Time: 62.26\n",
      "It: 170500, Loss: 8.790e-01, l1: 0.998, l2: 0.01040, Time: 62.30\n",
      "It: 171000, Loss: 1.022e+00, l1: 0.997, l2: 0.01039, Time: 62.27\n",
      "It: 171500, Loss: 9.458e-01, l1: 0.997, l2: 0.01042, Time: 62.21\n",
      "It: 172000, Loss: 8.747e-01, l1: 0.998, l2: 0.01040, Time: 62.20\n",
      "It: 172500, Loss: 1.358e+00, l1: 0.997, l2: 0.01033, Time: 62.19\n",
      "It: 173000, Loss: 8.862e-01, l1: 0.998, l2: 0.01041, Time: 62.26\n",
      "It: 173500, Loss: 1.099e+00, l1: 0.997, l2: 0.01042, Time: 62.23\n",
      "It: 174000, Loss: 8.639e-01, l1: 0.998, l2: 0.01041, Time: 62.27\n",
      "It: 174500, Loss: 8.684e-01, l1: 0.998, l2: 0.01041, Time: 62.29\n",
      "It: 175000, Loss: 8.785e-01, l1: 0.998, l2: 0.01040, Time: 62.32\n",
      "It: 175500, Loss: 8.905e-01, l1: 0.998, l2: 0.01041, Time: 62.26\n",
      "It: 176000, Loss: 9.493e-01, l1: 0.998, l2: 0.01040, Time: 62.28\n",
      "It: 176500, Loss: 1.265e+00, l1: 0.998, l2: 0.01042, Time: 62.28\n",
      "It: 177000, Loss: 8.826e-01, l1: 0.998, l2: 0.01042, Time: 62.27\n",
      "It: 177500, Loss: 1.052e+00, l1: 0.997, l2: 0.01041, Time: 62.27\n",
      "It: 178000, Loss: 8.461e-01, l1: 0.998, l2: 0.01041, Time: 62.25\n",
      "It: 178500, Loss: 8.465e-01, l1: 0.998, l2: 0.01041, Time: 62.33\n",
      "It: 179000, Loss: 9.217e-01, l1: 0.997, l2: 0.01039, Time: 62.23\n",
      "It: 179500, Loss: 8.894e-01, l1: 0.998, l2: 0.01039, Time: 62.30\n",
      "It: 180000, Loss: 1.183e+00, l1: 0.998, l2: 0.01035, Time: 62.27\n",
      "It: 180500, Loss: 8.371e-01, l1: 0.998, l2: 0.01041, Time: 62.23\n",
      "It: 181000, Loss: 8.387e-01, l1: 0.998, l2: 0.01041, Time: 62.30\n",
      "It: 181500, Loss: 9.577e-01, l1: 0.997, l2: 0.01041, Time: 62.25\n",
      "It: 182000, Loss: 8.371e-01, l1: 0.998, l2: 0.01041, Time: 62.32\n",
      "It: 182500, Loss: 8.397e-01, l1: 0.998, l2: 0.01042, Time: 62.26\n",
      "It: 183000, Loss: 8.297e-01, l1: 0.998, l2: 0.01041, Time: 62.29\n",
      "It: 183500, Loss: 8.993e-01, l1: 0.998, l2: 0.01043, Time: 62.30\n",
      "It: 184000, Loss: 8.609e-01, l1: 0.998, l2: 0.01042, Time: 62.27\n",
      "It: 184500, Loss: 8.339e-01, l1: 0.998, l2: 0.01042, Time: 62.29\n",
      "It: 185000, Loss: 2.290e+00, l1: 0.998, l2: 0.01032, Time: 62.27\n",
      "It: 185500, Loss: 8.169e-01, l1: 0.998, l2: 0.01041, Time: 62.29\n",
      "It: 186000, Loss: 8.157e-01, l1: 0.998, l2: 0.01041, Time: 62.28\n",
      "It: 186500, Loss: 8.239e-01, l1: 0.998, l2: 0.01041, Time: 62.31\n",
      "It: 187000, Loss: 8.108e-01, l1: 0.998, l2: 0.01041, Time: 62.29\n",
      "It: 187500, Loss: 8.088e-01, l1: 0.998, l2: 0.01042, Time: 62.27\n",
      "It: 188000, Loss: 1.172e+00, l1: 0.998, l2: 0.01045, Time: 62.24\n",
      "It: 188500, Loss: 9.067e-01, l1: 0.998, l2: 0.01044, Time: 62.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 189000, Loss: 8.025e-01, l1: 0.998, l2: 0.01041, Time: 62.29\n",
      "It: 189500, Loss: 8.353e-01, l1: 0.998, l2: 0.01042, Time: 62.31\n",
      "It: 190000, Loss: 8.133e-01, l1: 0.998, l2: 0.01042, Time: 62.28\n",
      "It: 190500, Loss: 9.450e-01, l1: 0.998, l2: 0.01041, Time: 62.29\n",
      "It: 191000, Loss: 8.246e-01, l1: 0.998, l2: 0.01043, Time: 62.27\n",
      "It: 191500, Loss: 8.067e-01, l1: 0.998, l2: 0.01042, Time: 62.29\n",
      "It: 192000, Loss: 7.945e-01, l1: 0.998, l2: 0.01042, Time: 62.27\n",
      "It: 192500, Loss: 8.150e-01, l1: 0.998, l2: 0.01042, Time: 62.25\n",
      "It: 193000, Loss: 8.048e-01, l1: 0.998, l2: 0.01042, Time: 62.29\n",
      "It: 193500, Loss: 7.898e-01, l1: 0.998, l2: 0.01042, Time: 62.22\n",
      "It: 194000, Loss: 7.893e-01, l1: 0.998, l2: 0.01043, Time: 62.30\n",
      "It: 194500, Loss: 1.564e+00, l1: 0.998, l2: 0.01048, Time: 62.30\n",
      "It: 195000, Loss: 1.182e+00, l1: 0.998, l2: 0.01052, Time: 62.26\n",
      "It: 195500, Loss: 7.831e-01, l1: 0.998, l2: 0.01042, Time: 62.26\n",
      "It: 196000, Loss: 7.935e-01, l1: 0.998, l2: 0.01043, Time: 62.29\n",
      "It: 196500, Loss: 1.901e+00, l1: 0.998, l2: 0.01051, Time: 62.24\n",
      "It: 197000, Loss: 7.807e-01, l1: 0.998, l2: 0.01043, Time: 62.28\n",
      "It: 197500, Loss: 7.849e-01, l1: 0.998, l2: 0.01042, Time: 62.25\n",
      "It: 198000, Loss: 8.083e-01, l1: 0.998, l2: 0.01040, Time: 62.26\n",
      "It: 198500, Loss: 9.082e-01, l1: 0.998, l2: 0.01040, Time: 62.26\n",
      "It: 199000, Loss: 7.726e-01, l1: 0.998, l2: 0.01042, Time: 62.24\n",
      "It: 199500, Loss: 8.055e-01, l1: 0.998, l2: 0.01040, Time: 62.27\n",
      "Loss: 7.665e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 6.571e+04, l1: 1.000, l2: 0.00941\n",
      "Loss: 7.637e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "Loss: 7.636e-01, l1: 0.998, l2: 0.01042\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.763609\n",
      "  Number of iterations: 8\n",
      "  Number of functions evaluations: 24\n",
      "Error u: 6.011515e-03\n",
      "Error v: 1.698996e-02\n",
      "Error p: 4.221677e+00\n",
      "Error l1: 0.22430%\n",
      "Error l2: 4.21092%\n"
     ]
    }
   ],
   "source": [
    "N_train = 5000\n",
    "\n",
    "layers = [3, 20, 20, 20, 20, 20, 20, 20, 20, 2]\n",
    "\n",
    "# Load Data\n",
    "data = scipy.io.loadmat('Data/cylinder_nektar_wake.mat')\n",
    "\n",
    "U_star = data['U_star'] # N x 2 x T\n",
    "P_star = data['p_star'] # N x T\n",
    "t_star = data['t'] # T x 1\n",
    "X_star = data['X_star'] # N x 2\n",
    "\n",
    "N = X_star.shape[0]\n",
    "T = t_star.shape[0]\n",
    "\n",
    "# Rearrange Data \n",
    "XX = np.tile(X_star[:,0:1], (1,T)) # N x T\n",
    "YY = np.tile(X_star[:,1:2], (1,T)) # N x T\n",
    "TT = np.tile(t_star, (1,N)).T # N x T\n",
    "\n",
    "UU = U_star[:,0,:] # N x T\n",
    "VV = U_star[:,1,:] # N x T\n",
    "PP = P_star # N x T\n",
    "\n",
    "x = XX.flatten()[:,None] # NT x 1\n",
    "y = YY.flatten()[:,None] # NT x 1\n",
    "t = TT.flatten()[:,None] # NT x 1\n",
    "\n",
    "u = UU.flatten()[:,None] # NT x 1\n",
    "v = VV.flatten()[:,None] # NT x 1\n",
    "p = PP.flatten()[:,None] # NT x 1\n",
    "\n",
    "######################################################################\n",
    "######################## Noiseles Data ###############################\n",
    "######################################################################\n",
    "# Training Data    \n",
    "idx = np.random.choice(N*T, N_train, replace=False)\n",
    "x_train = x[idx,:]\n",
    "y_train = y[idx,:]\n",
    "t_train = t[idx,:]\n",
    "u_train = u[idx,:]\n",
    "v_train = v[idx,:]\n",
    "\n",
    "# Training\n",
    "model = PhysicsInformedNN(x_train, y_train, t_train, u_train, v_train, layers)\n",
    "model.train(200000)\n",
    "\n",
    "# Test Data\n",
    "snap = np.array([100])\n",
    "x_star = X_star[:,0:1]\n",
    "y_star = X_star[:,1:2]\n",
    "t_star = TT[:,snap]\n",
    "\n",
    "u_star = U_star[:,0,snap]\n",
    "v_star = U_star[:,1,snap]\n",
    "p_star = P_star[:,snap]\n",
    "\n",
    "# Prediction\n",
    "u_pred, v_pred, p_pred = model.predict(x_star, y_star, t_star)\n",
    "lambda_1_value = model.sess.run(model.lambda_1)\n",
    "lambda_2_value = model.sess.run(model.lambda_2)\n",
    "\n",
    "# Error\n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
    "error_p = np.linalg.norm(p_star-p_pred,2)/np.linalg.norm(p_star,2)\n",
    "\n",
    "error_lambda_1 = np.abs(lambda_1_value - 1.0)*100\n",
    "error_lambda_2 = np.abs(lambda_2_value - 0.01)/0.01 * 100\n",
    "\n",
    "print('Error u: %e' % (error_u))    \n",
    "print('Error v: %e' % (error_v))    \n",
    "print('Error p: %e' % (error_p))    \n",
    "print('Error l1: %.5f%%' % (error_lambda_1))                             \n",
    "print('Error l2: %.5f%%' % (error_lambda_2))                  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7-tensorflow1.14",
   "language": "python",
   "name": "python3.7-tensorflow1.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
